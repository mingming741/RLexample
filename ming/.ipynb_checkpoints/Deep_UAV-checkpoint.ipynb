{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "import random\n",
    "from random import randint, choice\n",
    "import matplotlib.pyplot as plt\n",
    "from util import *\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UAVEnvironment:\n",
    "    \"\"\"\n",
    "    Game environment for UAV test\n",
    "    \n",
    "    ---Map---\n",
    "    \n",
    "    y-axis(length)\n",
    "    |\n",
    "    |\n",
    "    |\n",
    "    |\n",
    "    |\n",
    "    |\n",
    "     _______________________ x-axis(width)\n",
    "     \n",
    "    Hight is a fixed value\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        # Game config\n",
    "        self.action_space = (0, 1, 2, 3) # up, right, down, left, total 4 actions\n",
    "        self.total_steps = config[\"total_steps\"] # when the game end\n",
    "        self.current_step = 0\n",
    "        if config[\"is_random_env\"] == False:\n",
    "            self.random_seed = config[\"random_seed\"]\n",
    "            random.seed(self.random_seed)\n",
    "        \n",
    "        # Map config\n",
    "        self.map = dict(width=config[\"map\"][\"width\"], length=config[\"map\"][\"length\"], height=config[\"map\"][\"height\"])\n",
    "        self.UAV_speed = config[\"UAV_speed\"]\n",
    "        self.UAV_initial_pos = config[\"UAV_initial_pos\"] # a tuple\n",
    "        self.UAV_current_pos = self.UAV_initial_pos\n",
    "        self.number_of_user = config[\"number_of_user\"]\n",
    "        self.users_pos = list()\n",
    "        for i in range(0, self.number_of_user):\n",
    "            self.users_pos.append((randint(0, self.map[\"width\"]), randint(0, self.map[\"length\"])))\n",
    "        \n",
    "        # Wireless config\n",
    "        self.g0 = config[\"wireless_parameter\"][\"g0\"]\n",
    "        self.B = config[\"wireless_parameter\"][\"B\"]\n",
    "        self.Pk = config[\"wireless_parameter\"][\"Pk\"]\n",
    "        self.noise = config[\"wireless_parameter\"][\"noise\"]\n",
    "        \n",
    "    def get_reward(self, UAV_pos):\n",
    "        # One step Reward is define as the summation of all user's utility\n",
    "        reward = 0\n",
    "        for user_index in range(0, self.number_of_user):\n",
    "            gkm = self.g0 / (self.map[\"height\"] ** 2 + (UAV_pos[0] - self.users_pos[user_index][0]) ** 2 + (UAV_pos[1] - self.users_pos[user_index][1]) ** 2)\n",
    "            user_utility = self.B * math.log(1 + self.Pk * gkm / self.noise, 2)\n",
    "            reward = reward + user_utility\n",
    "        return reward / (10 ** 6) # Use Mkbps as signal basic unit\n",
    "    \n",
    "    def transition_dynamics(self, action, speed, state):\n",
    "        # given the action (direction), calculate the next state (UAV current position)\n",
    "        assert action in self.action_space\n",
    "        next_UAV_pos = list(state)\n",
    "        if action == 0:\n",
    "            # move up\n",
    "            next_UAV_pos[1] = min(next_UAV_pos[1] + speed, self.map[\"length\"])\n",
    "        if action == 1:\n",
    "            # move right\n",
    "            next_UAV_pos[0] = min(next_UAV_pos[0] + speed, self.map[\"width\"])\n",
    "        if action == 2:\n",
    "            # move down\n",
    "            next_UAV_pos[1] = max(next_UAV_pos[1] - speed, 0)\n",
    "        if action == 3:\n",
    "            # move left\n",
    "            next_UAV_pos[0] = max(next_UAV_pos[0] - speed, 0)\n",
    "        return tuple(next_UAV_pos)\n",
    "    \n",
    "    def get_transition(self):\n",
    "        # This function only works for model based, we are trying to disable this function to try more algorithm\n",
    "        # Return a table of transition, we assume UAV use fixed flying speed\n",
    "        \"\"\"\n",
    "        Structure:\n",
    "        transition[\n",
    "            x_0[\n",
    "                y_0[\n",
    "                    {next_state, reward}, # for action 1\n",
    "                    {next_state, reward}, # for action 2\n",
    "                    ...\n",
    "                    {next_state, reward}, # for action 20\n",
    "                ],\n",
    "                y_1*v[],\n",
    "                ...\n",
    "                y_h-1*v[]\n",
    "            ],\n",
    "            x_1*v[],\n",
    "            x_2*v[],\n",
    "            ...\n",
    "            x_w-1*v[]\n",
    "        ]\n",
    "        \n",
    "        \"\"\"\n",
    "        transition = list()\n",
    "        for state_x in range(0, int(self.map[\"width\"] / self.UAV_speed) + 1):\n",
    "            transition.append(list())\n",
    "            for state_y in range(0, int(self.map[\"length\"] / self.UAV_speed) + 1):\n",
    "                transition[state_x].append(list())\n",
    "                for action in self.action_space:\n",
    "                    next_state = self.transition_dynamics(action, self.UAV_speed, (state_x * self.UAV_speed, state_y * self.UAV_speed))\n",
    "                    reward = self.get_reward(next_state)\n",
    "                    transition[state_x][state_y].append(dict(next_state=next_state,reward=reward))\n",
    "        return transition\n",
    "                    \n",
    "    def step(self, action, speed=-1):\n",
    "        # assume we use the max speed as the default speed, when come near to the opt-position, we can slow down the speed\n",
    "        if speed < 0 or speed >= self.UAV_speed:\n",
    "            speed = self.UAV_speed\n",
    "            \n",
    "        self.UAV_current_pos = self.transition_dynamics(action, speed, self.UAV_current_pos)\n",
    "        self.current_step = self.current_step + 1\n",
    "        done = False\n",
    "        if self.current_step == self.total_steps:\n",
    "            done =  True\n",
    "        return self.UAV_current_pos, self.get_reward(self.UAV_current_pos), done\n",
    "    \n",
    "    def action_sample(self):\n",
    "        return choice(self.action_space)\n",
    "    \n",
    "    def reset(self):\n",
    "        self.current_step = 0\n",
    "        self.UAV_current_pos = self.UAV_initial_pos\n",
    "        #self.users_pos = list()\n",
    "        #for i in range(0, self.number_of_user):\n",
    "        #    self.users_pos.append((randint(0, self.map[\"width\"]), randint(0, self.map[\"length\"])))\n",
    "        return self.UAV_current_pos\n",
    "        \n",
    "    def print_attribute(self):\n",
    "        attrs = vars(self)\n",
    "        print(', '.join(\"%s: %s\" % item for item in attrs.items()))\n",
    "        \n",
    "    def print_map(self):\n",
    "        x_list = [pos[0] for pos in self.users_pos]\n",
    "        y_list = [pos[1] for pos in self.users_pos]\n",
    "        x_list.append(self.UAV_current_pos[0])\n",
    "        y_list.append(self.UAV_current_pos[1])\n",
    "        \n",
    "        colors = np.array([\"red\", \"green\"])\n",
    "        sizes = []\n",
    "        colors_map = []\n",
    "        for i in range(0, self.number_of_user):\n",
    "            sizes.append(25)\n",
    "            colors_map.append(1)\n",
    "        sizes.append(50)\n",
    "        colors_map.append(0)\n",
    "        plt.scatter(x_list, y_list, c=colors[colors_map], s=sizes) \n",
    "        plt.axis([0, self.map[\"width\"], 0, self.map[\"length\"]])\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment_config = dict(\n",
    "    total_steps = 10,\n",
    "    random_seed = 0,\n",
    "    is_random_env = False,\n",
    "    map=dict(\n",
    "        width=1000,\n",
    "        length=1000,\n",
    "        height=100\n",
    "    ),\n",
    "    number_of_user = 10,\n",
    "    UAV_speed = 20,\n",
    "    UAV_initial_pos = (0, 0),\n",
    "    wireless_parameter = dict(\n",
    "        g0 = 10 ** (-5),\n",
    "        B = 10 ** (6),\n",
    "        Pk = 0.1,\n",
    "        noise = 10 ** (-9)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action_space: (0, 1, 2, 3), total_steps: 10, current_step: 0, random_seed: 0, map: {'width': 1000, 'length': 1000, 'height': 100}, UAV_speed: 20, UAV_initial_pos: (0, 0), UAV_current_pos: (0, 0), number_of_user: 10, users_pos: [(864, 394), (776, 911), (430, 41), (265, 988), (523, 497), (414, 940), (802, 849), (310, 991), (488, 366), (597, 913)], g0: 1e-05, B: 1000000, Pk: 0.1, noise: 1e-09\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "myGame = UAVEnvironment(environment_config)\n",
    "myGame.print_attribute()\n",
    "myGame.print_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(policy, config, num_episodes=1, render=False):\n",
    "    env = UAVEnvironment(config)\n",
    "    \n",
    "    rewards = []\n",
    "    for i in range(num_episodes):\n",
    "        obs = env.reset()\n",
    "        # all policy will return a direction and a speed\n",
    "        act_direction, act_speed = policy(obs)\n",
    "        ep_reward = 0\n",
    "        while True:\n",
    "            obs, reward, done = env.step(act_direction, act_speed)\n",
    "            act_direction, act_speed = policy(obs)\n",
    "            ep_reward += reward\n",
    "            if done:\n",
    "                break\n",
    "            if render = True:\n",
    "                clear_output(wait=True)\n",
    "                env.print_attribute()\n",
    "                print(\"Current Step: {}\".format(env.current_step))\n",
    "                print(\"Policy choice direction: {}, speed: {}\".format(act_direction, act_speed))\n",
    "                print(\"UAV current position x: {}, y: {}\".format(env.UAV_current_pos[0], env.UAV_current_pos[1]))\n",
    "                print(\"Current step reward: {}, episodes rewards: {}\".format(reward, ep_reward))\n",
    "                env.print_map()\n",
    "                wait(sleep=0.2)\n",
    "        rewards.append(ep_reward)\n",
    "    return np.mean(rewards)\n",
    "\n",
    "def run(trainer_cls, config=None, reward_threshold=None):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Class for all RL algorithm\n",
    "class UAVTrainer: \n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.env = UAVEnvironment(self.config)\n",
    "    \n",
    "    def train(self):\n",
    "        pass\n",
    "    \n",
    "    def policy(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action_space: (0, 1, 2, 3), total_steps: 10, current_step: 0, random_seed: 0, map: {'width': 120, 'length': 60, 'height': 100}, UAV_speed: 20, UAV_initial_pos: (0, 0), UAV_current_pos: (0, 0), number_of_user: 1, users_pos: [(108, 24)], g0: 1e-05, B: 1000000, Pk: 0.1, noise: 1e-09\n",
      "Mean Reward is: 0.6778269285353753\n"
     ]
    }
   ],
   "source": [
    "# Start from random policy\n",
    "class UAVTrainerRandomPolicy(UAVTrainer):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        \n",
    "    def policy(self, obs):\n",
    "        max_speed = self.env.UAV_speed\n",
    "        return self.env.action_sample(), max_speed\n",
    "\n",
    "random_policy_config = environment_config\n",
    "trainer = UAVTrainerRandomPolicy(random_policy_config)\n",
    "trainer.env.print_attribute()\n",
    "print(\"Mean Reward is: {}\".format(evaluate(trainer.policy, config = random_policy_config, num_episodes=1, render=False))) # Enable render=True can see the agent behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 524,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action_space: (0, 1, 2, 3), total_steps: 50, current_step: 0, random_seed: 10, map: {'width': 1000, 'length': 1000, 'height': 100}, UAV_speed: 20, UAV_initial_pos: (0, 0), UAV_current_pos: (0, 0), number_of_user: 10, users_pos: [(585, 33), (439, 494), (591, 15), (211, 473), (832, 503), (843, 284), (669, 830), (164, 35), (533, 501), (335, 77)], g0: 1e-05, B: 1000000, Pk: 0.1, noise: 1e-09\n",
      "Iteration 100, Mean Reward is: 12.21220913177311\n",
      "Iteration 200, Mean Reward is: 12.21220913177311\n",
      "Train converge at i = 200\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "# Value Iteration, Tabular, transition dynamic is known, assume only use fixed speed to reduce action space\n",
    "class UAVTrainerValueIteration(UAVTrainer):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.config = config\n",
    "        self.transitions = self.env.get_transition()\n",
    "        self.q_table = []\n",
    "        self.obs_dim = (int(self.env.map[\"width\"] / self.env.UAV_speed), int(self.env.map[\"length\"] / self.env.UAV_speed))\n",
    "        self.act_dim = len(self.env.action_space)\n",
    "        self.gamma = config[\"gamma\"]\n",
    "        \n",
    "        for x in range(0, self.obs_dim[0]+1):\n",
    "            self.q_table.append(list())\n",
    "            for y in range(0, self.obs_dim[1]+1):\n",
    "                self.q_table[x].append(0)\n",
    "            \n",
    "    def get_transition(self, state, act):\n",
    "        transition = self.transitions[state[0]][state[1]][act]\n",
    "        return transition[\"next_state\"], transition[\"reward\"]\n",
    "    \n",
    "    def print_transitions(self):\n",
    "        print(\"Transition width {}, length {}, number of act {}\".format(len(self.transitions), len(self.transitions[0]), len(self.transitions[0][0])))\n",
    "        print(self.transitions)\n",
    "        \n",
    "    def print_table(self):\n",
    "        for j in range(len(self.q_table[0])-1, -1, -1):\n",
    "            for i in range(0, len(self.q_table)):\n",
    "                print(self.q_table[i][j], end =\" \")\n",
    "            print(\"\")\n",
    "            \n",
    "            \n",
    "    def copy_current_table(self):\n",
    "        old_table = []\n",
    "        for x in range(0, self.obs_dim[0]+1):\n",
    "            old_table.append(list())\n",
    "            for y in range(0, self.obs_dim[1]+1):\n",
    "                old_table[x].append(self.q_table[x][y])\n",
    "        return old_table\n",
    "\n",
    "    def update_value_function(self):\n",
    "        old_table = self.copy_current_table()\n",
    "        for state_x in range(self.obs_dim[0] + 1):\n",
    "            for state_y in range(self.obs_dim[1] + 1):\n",
    "                state_value = 0\n",
    "                state_action_values = [0 for i in range(0, self.act_dim)]\n",
    "\n",
    "                for act in range(self.act_dim):\n",
    "                    next_state, reward = self.get_transition((state_x, state_y), act)\n",
    "                    table_x = int(next_state[0] / self.env.UAV_speed)\n",
    "                    table_y = int(next_state[1] / self.env.UAV_speed)\n",
    "                    #print(table_x, table_y)\n",
    "                    state_action_values[act] = state_action_values[act] + reward + self.gamma * old_table[table_x][table_y]   \n",
    "                state_value = np.max(state_action_values)\n",
    "                self.q_table[state_x][state_y] = state_value\n",
    "                #print(\"Update x: {}, y: {} to value {}\".format(state_x, state_y, state_value))\n",
    "            \n",
    "    def train(self):\n",
    "        old_state_value_table = self.copy_current_table()\n",
    "        current_step = 0\n",
    "        while current_step < self.config['max_iteration']:  \n",
    "            current_step = current_step + 1\n",
    "            self.update_value_function()\n",
    "            if current_step % self.config[\"evaluate_interval\"] == 0:\n",
    "                print(\"Iteration {}, Mean Reward is: {}\".format(current_step, evaluate(self.policy, config = self.config, num_episodes=1, render=False)))\n",
    "                #print(\"Iteration {}, Mean Reward is: {}\".format(current_step, 0))\n",
    "                # check exist\n",
    "                stop = True\n",
    "                flag = 0\n",
    "                for x in range(self.obs_dim[0] + 1):\n",
    "                    for y in range(self.obs_dim[1] + 1):\n",
    "                        if abs(self.q_table[x][y] - old_state_value_table[x][y]) > self.config[\"return_threshold\"]:\n",
    "                            stop = False\n",
    "                            flag = 1\n",
    "                    if flag == 1:\n",
    "                        break\n",
    "                if stop == True:\n",
    "                    print(\"Train converge at i = {}\".format(current_step))\n",
    "                    current_step = self.config['max_iteration']\n",
    "                else:\n",
    "                    old_state_value_table = self.copy_current_table()\n",
    "\n",
    "    def policy(self, obs):\n",
    "        table_x = int(obs[0] / self.env.UAV_speed)\n",
    "        table_y = int(obs[1] / self.env.UAV_speed)\n",
    "        next_state_value_list = []\n",
    "        for act in range(0, self.act_dim):\n",
    "            next_state, reward = self.get_transition((table_x, table_y), act)\n",
    "            next_state_x = int(next_state[0] / self.env.UAV_speed)\n",
    "            next_state_y = int(next_state[1] / self.env.UAV_speed)\n",
    "            next_state_value_list.append(self.q_table[next_state_x][next_state_y])\n",
    "        #print(next_state_value_list, act)\n",
    "        act = np.argmax(next_state_value_list)\n",
    "        return act, self.env.UAV_speed\n",
    "\n",
    "value_iteration_config = merge_config(dict(\n",
    "    max_iteration=10000,\n",
    "    total_steps = 50,\n",
    "    number_of_user = 10,\n",
    "    map=dict(\n",
    "        width=1000,\n",
    "        length=1000,\n",
    "        height=10000\n",
    "    ),\n",
    "    evaluate_interval=100,  # don't need to update policy each iteration\n",
    "    gamma=0.9,\n",
    "    return_threshold=1,\n",
    "    random_seed = 10,\n",
    "    is_random_env = False\n",
    "), environment_config)\n",
    "trainer = UAVTrainerValueIteration(value_iteration_config)\n",
    "trainer.env.print_attribute()\n",
    "#trainer.print_transitions()\n",
    "trainer.train()\n",
    "#trainer.print_table()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 525,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action_space: (0, 1, 2, 3), total_steps: 50, current_step: 49, random_seed: 10, map: {'width': 1000, 'length': 1000, 'height': 100}, UAV_speed: 20, UAV_initial_pos: (0, 0), UAV_current_pos: (580, 40), number_of_user: 10, users_pos: [(585, 33), (439, 494), (591, 15), (211, 473), (832, 503), (843, 284), (669, 830), (164, 35), (533, 501), (335, 77)], g0: 1e-05, B: 1000000, Pk: 0.1, noise: 1e-09\n",
      "Current Step: 49\n",
      "Policy choice direction: 0, speed: 20\n",
      "UAV current position x: 580, y: 40\n",
      "Current step reward: 0.32727087627210383, episodes rewards: 11.90466590667555\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Reward is: 12.21220913177311\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean Reward is: {}\".format(evaluate(trainer.policy, config = value_iteration_config, num_episodes=1, render=True))) # Enable render=True can see the agent behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random number with seed 30\n",
      "first -  37\n",
      "Second -  49\n",
      "Third -  37\n",
      "Third -  49\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "print (\"Random number with seed 30\")\n",
    "random.seed(0)\n",
    "print (\"first - \", random.randint(25,50))\n",
    "\n",
    "#will generate a same random number as previous\n",
    "print (\"Second - \", random.randint(25,50))\n",
    "\n",
    "#will generate a same random number as previous\n",
    "random.seed(0)\n",
    "print (\"Third - \", random.randint(25,50))\n",
    "print (\"Third - \", random.randint(25,50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
