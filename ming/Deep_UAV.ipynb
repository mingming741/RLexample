{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "import random\n",
    "from random import randint, choice\n",
    "import matplotlib.pyplot as plt\n",
    "from util import *\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UAVEnvironment():\n",
    "    \"\"\"\n",
    "    Game environment for UAV test\n",
    "    \n",
    "    ---Map---\n",
    "    \n",
    "    y-axis(length)\n",
    "    |\n",
    "    |\n",
    "    |\n",
    "    |\n",
    "    |\n",
    "    |\n",
    "     _______________________ x-axis(width)\n",
    "     \n",
    "    Hight is a fixed value\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        # Game config\n",
    "        self.action_space = (0, 1, 2, 3) # up, right, down, left, total 4 actions\n",
    "        self.total_steps = config[\"total_steps\"] # when the game end\n",
    "        self.current_step = 0\n",
    "        if config[\"is_random_env\"] == False:\n",
    "            self.random_seed = config[\"random_seed\"]\n",
    "            random.seed(self.random_seed)\n",
    "        \n",
    "        # Map config\n",
    "        self.map = dict(width=config[\"map\"][\"width\"], length=config[\"map\"][\"length\"], height=config[\"map\"][\"height\"])\n",
    "        self.UAV_speed = config[\"UAV_speed\"]\n",
    "        self.UAV_initial_pos = config[\"UAV_initial_pos\"] # a tuple\n",
    "        self.UAV_current_pos = self.UAV_initial_pos\n",
    "        self.number_of_user = config[\"number_of_user\"]\n",
    "        self.users_pos = list()\n",
    "        self.UAV_path = [] # record the path of UAV\n",
    "        for i in range(0, self.number_of_user):\n",
    "            self.users_pos.append((randint(0, self.map[\"width\"]), randint(0, self.map[\"length\"])))\n",
    "        \n",
    "        # Wireless config\n",
    "        self.g0 = config[\"wireless_parameter\"][\"g0\"]\n",
    "        self.B = config[\"wireless_parameter\"][\"B\"]\n",
    "        self.Pk = config[\"wireless_parameter\"][\"Pk\"]\n",
    "        self.noise = config[\"wireless_parameter\"][\"noise\"]\n",
    "        \n",
    "    def get_reward(self, UAV_pos):\n",
    "        # One step Reward is define as the summation of all user's utility\n",
    "        reward = 0\n",
    "        for user_index in range(0, self.number_of_user):\n",
    "            gkm = self.g0 / (self.map[\"height\"] ** 2 + (UAV_pos[0] - self.users_pos[user_index][0]) ** 2 + (UAV_pos[1] - self.users_pos[user_index][1]) ** 2)\n",
    "            user_utility = self.B * math.log(1 + self.Pk * gkm / self.noise, 2)\n",
    "            reward = reward + user_utility\n",
    "        return reward / (10 ** 6) # Use Mkbps as signal basic unit\n",
    "    \n",
    "    def transition_dynamics(self, action, speed, state):\n",
    "        # given the action (direction), calculate the next state (UAV current position)\n",
    "        assert action in self.action_space\n",
    "        next_UAV_pos = list(state)\n",
    "        if action == 0:\n",
    "            # move up\n",
    "            next_UAV_pos[1] = min(next_UAV_pos[1] + speed, self.map[\"length\"])\n",
    "        if action == 1:\n",
    "            # move right\n",
    "            next_UAV_pos[0] = min(next_UAV_pos[0] + speed, self.map[\"width\"])\n",
    "        if action == 2:\n",
    "            # move down\n",
    "            next_UAV_pos[1] = max(next_UAV_pos[1] - speed, 0)\n",
    "        if action == 3:\n",
    "            # move left\n",
    "            next_UAV_pos[0] = max(next_UAV_pos[0] - speed, 0)\n",
    "        return tuple(next_UAV_pos)\n",
    "    \n",
    "    def get_transition(self):\n",
    "        # This function only works for model based, we are trying to disable this function to try more algorithm\n",
    "        # Return a table of transition, we assume UAV use fixed flying speed\n",
    "        \"\"\"\n",
    "        Structure:\n",
    "        transition[\n",
    "            x_0[\n",
    "                y_0[\n",
    "                    {next_state, reward}, # for action 1\n",
    "                    {next_state, reward}, # for action 2\n",
    "                    ...\n",
    "                    {next_state, reward}, # for action 20\n",
    "                ],\n",
    "                y_1*v[],\n",
    "                ...\n",
    "                y_h-1*v[]\n",
    "            ],\n",
    "            x_1*v[],\n",
    "            x_2*v[],\n",
    "            ...\n",
    "            x_w-1*v[]\n",
    "        ]\n",
    "        \"\"\"\n",
    "        transition = list()\n",
    "        for state_x in range(0, int(self.map[\"width\"] / self.UAV_speed) + 1):\n",
    "            transition.append(list())\n",
    "            for state_y in range(0, int(self.map[\"length\"] / self.UAV_speed) + 1):\n",
    "                transition[state_x].append(list())\n",
    "                for action in self.action_space:\n",
    "                    next_state = self.transition_dynamics(action, self.UAV_speed, (state_x * self.UAV_speed, state_y * self.UAV_speed))\n",
    "                    reward = self.get_reward(next_state)\n",
    "                    transition[state_x][state_y].append(dict(next_state=next_state,reward=reward))\n",
    "        return transition\n",
    "                    \n",
    "    def step(self, action, speed=-1):\n",
    "        # assume we use the max speed as the default speed, when come near to the opt-position, we can slow down the speed\n",
    "        if speed < 0 or speed >= self.UAV_speed:\n",
    "            speed = self.UAV_speed\n",
    "            \n",
    "        self.UAV_path.append(self.UAV_current_pos)\n",
    "        self.UAV_current_pos = self.transition_dynamics(action, speed, self.UAV_current_pos)\n",
    "        self.current_step = self.current_step + 1\n",
    "        done = False\n",
    "        if self.current_step == self.total_steps:\n",
    "            done =  True\n",
    "        return self.UAV_current_pos, self.get_reward(self.UAV_current_pos), done\n",
    "    \n",
    "    def action_sample(self):\n",
    "        return choice(self.action_space)\n",
    "    \n",
    "    def reset(self):\n",
    "        self.current_step = 0\n",
    "        self.UAV_current_pos = self.UAV_initial_pos\n",
    "        return self.UAV_current_pos\n",
    "        \n",
    "    def print_attribute(self):\n",
    "        attrs = vars(self)\n",
    "        print(', '.join(\"%s: %s\" % item for item in attrs.items()))\n",
    "        \n",
    "    def print_locations(self):\n",
    "        print(\"UAV position is: {}\".format(self.UAV_current_pos))\n",
    "        print(\"Users position are: {}\".format(self.users_pos))\n",
    "        \n",
    "    def print_map(self):\n",
    "        x_list = [pos[0] for pos in self.users_pos]\n",
    "        y_list = [pos[1] for pos in self.users_pos]\n",
    "        x_list.append(self.UAV_current_pos[0])\n",
    "        y_list.append(self.UAV_current_pos[1])\n",
    "        for i in range(0, len(self.UAV_path)):\n",
    "            x_list.append(self.UAV_path[i][0])\n",
    "            y_list.append(self.UAV_path[i][1])\n",
    "        \n",
    "        colors = np.array([\"red\", \"green\", \"blue\"])\n",
    "        sizes = []\n",
    "        colors_map = []\n",
    "        for i in range(0, self.number_of_user):\n",
    "            sizes.append(25)\n",
    "            colors_map.append(1)\n",
    "        sizes.append(50)\n",
    "        colors_map.append(0)\n",
    "        for i in range(0, len(self.UAV_path)):\n",
    "            sizes.append(10)\n",
    "            colors_map.append(2)\n",
    "        for i in range(0, len(self.UAV_path) - 1):\n",
    "            x_values = [self.UAV_path[i][0], self.UAV_path[i+1][0]]\n",
    "            y_values = [self.UAV_path[i][1], self.UAV_path[i+1][1]]\n",
    "            plt.plot(x_values, y_values, 'b')\n",
    "        plt.scatter(x_list, y_list, c=colors[colors_map], s=sizes) \n",
    "        plt.axis([0, self.map[\"width\"], 0, self.map[\"length\"]])\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment_config = dict(\n",
    "    total_steps = 50,\n",
    "    random_seed = 20,\n",
    "    is_random_env = False,\n",
    "    map=dict(\n",
    "        width=1000,\n",
    "        length=1000,\n",
    "        height=100\n",
    "    ),\n",
    "    number_of_user = 10,\n",
    "    UAV_speed = 50,\n",
    "    UAV_initial_pos = (0, 0),\n",
    "    wireless_parameter = dict(\n",
    "        g0 = 10 ** (-5),\n",
    "        B = 10 ** (6),\n",
    "        Pk = 0.1,\n",
    "        noise = 10 ** (-9)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action_space: (0, 1, 2, 3), total_steps: 50, current_step: 0, random_seed: 20, map: {'width': 1000, 'length': 1000, 'height': 100}, UAV_speed: 50, UAV_initial_pos: (0, 0), UAV_current_pos: (0, 0), number_of_user: 10, users_pos: [(927, 740), (702, 805), (784, 901), (926, 154), (266, 690), (650, 869), (926, 103), (893, 335), (586, 927), (173, 27)], UAV_path: [], g0: 1e-05, B: 1000000, Pk: 0.1, noise: 1e-09\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "myGame = UAVEnvironment(environment_config)\n",
    "myGame.print_attribute()\n",
    "myGame.print_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(policy, config, num_episodes=1, render=False):\n",
    "    env = UAVEnvironment(config)\n",
    "    \n",
    "    rewards = []\n",
    "    for i in range(num_episodes):\n",
    "        obs = env.reset()\n",
    "        # all policy will return a direction and a speed\n",
    "        act_direction, act_speed = policy(obs)\n",
    "        ep_reward = 0\n",
    "        while True:\n",
    "            obs, reward, done = env.step(act_direction, act_speed)\n",
    "            act_direction, act_speed = policy(obs)\n",
    "            ep_reward += reward\n",
    "            if done:\n",
    "                break\n",
    "            if render == True:\n",
    "                clear_output(wait=True)\n",
    "                env.print_attribute()\n",
    "                print(\"Current Step: {}\".format(env.current_step))\n",
    "                print(\"Policy choice direction: {}, speed: {}\".format(act_direction, act_speed))\n",
    "                print(\"UAV current position x: {}, y: {}\".format(env.UAV_current_pos[0], env.UAV_current_pos[1]))\n",
    "                print(\"Current step reward: {}, episodes rewards: {}\".format(reward, ep_reward))\n",
    "                env.print_map()\n",
    "                wait(sleep=0.2)\n",
    "        rewards.append(ep_reward)\n",
    "    return np.mean(rewards)\n",
    "\n",
    "def run(trainer_cls, config=None, reward_threshold=None):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UAV position is: (0, 0)\n",
      "Users position are: [(927, 740), (702, 805), (784, 901), (926, 154), (266, 690), (650, 869), (926, 103), (893, 335), (586, 927), (173, 27)]\n",
      "Mean Reward is: 3.205710568501357\n"
     ]
    }
   ],
   "source": [
    "# Basic Class for all RL algorithm\n",
    "class UAVTrainer: \n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.env = UAVEnvironment(self.config)\n",
    "\n",
    "# Start from random policy\n",
    "class UAVTrainerRandomPolicy(UAVTrainer):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        \n",
    "    def policy(self, obs):\n",
    "        max_speed = self.env.UAV_speed\n",
    "        return self.env.action_sample(), max_speed\n",
    "\n",
    "random_policy_config = environment_config\n",
    "trainer = UAVTrainerRandomPolicy(random_policy_config)\n",
    "trainer.env.print_locations()\n",
    "print(\"Mean Reward is: {}\".format(evaluate(trainer.policy, config = random_policy_config, num_episodes=1, render=False))) # Enable render=True can see the agent behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UAV position is: (0, 0)\n",
      "Users position are: [(386, 786), (949, 863), (863, 15), (219, 953), (892, 312), (651, 484), (43, 878), (975, 775), (261, 35), (313, 578)]\n",
      "Iteration 100, Mean Reward is: 6.315389433958716\n",
      "Iteration 200, Mean Reward is: 6.315389433958716\n",
      "Train converge at i = 200\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "# Value Iteration, Tabular, transition dynamic is known, assume only use fixed speed to reduce action space\n",
    "class UAVTrainerValueIteration(UAVTrainer):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.config = config\n",
    "        self.transitions = self.env.get_transition()\n",
    "        self.q_table = []\n",
    "        self.obs_dim = (int(self.env.map[\"width\"] / self.env.UAV_speed), int(self.env.map[\"length\"] / self.env.UAV_speed))\n",
    "        self.act_dim = len(self.env.action_space)\n",
    "        self.gamma = config[\"gamma\"]\n",
    "        \n",
    "        for x in range(0, self.obs_dim[0]+1):\n",
    "            self.q_table.append(list())\n",
    "            for y in range(0, self.obs_dim[1]+1):\n",
    "                self.q_table[x].append(0)\n",
    "            \n",
    "    def get_transition(self, state, act):\n",
    "        transition = self.transitions[state[0]][state[1]][act]\n",
    "        return transition[\"next_state\"], transition[\"reward\"]\n",
    "    \n",
    "    def print_transitions(self):\n",
    "        print(\"Transition width {}, length {}, number of act {}\".format(len(self.transitions), len(self.transitions[0]), len(self.transitions[0][0])))\n",
    "        print(self.transitions)\n",
    "        \n",
    "    def print_table(self):\n",
    "        for j in range(len(self.q_table[0])-1, -1, -1):\n",
    "            for i in range(0, len(self.q_table)):\n",
    "                print(self.q_table[i][j], end =\" \")\n",
    "            print(\"\")\n",
    "            \n",
    "            \n",
    "    def copy_current_table(self):\n",
    "        old_table = []\n",
    "        for x in range(0, self.obs_dim[0]+1):\n",
    "            old_table.append(list())\n",
    "            for y in range(0, self.obs_dim[1]+1):\n",
    "                old_table[x].append(self.q_table[x][y])\n",
    "        return old_table\n",
    "\n",
    "    def update_value_function(self):\n",
    "        old_table = self.copy_current_table()\n",
    "        for state_x in range(self.obs_dim[0] + 1):\n",
    "            for state_y in range(self.obs_dim[1] + 1):\n",
    "                state_value = 0\n",
    "                state_action_values = [0 for i in range(0, self.act_dim)]\n",
    "\n",
    "                for act in range(self.act_dim):\n",
    "                    next_state, reward = self.get_transition((state_x, state_y), act)\n",
    "                    table_x = int(next_state[0] / self.env.UAV_speed)\n",
    "                    table_y = int(next_state[1] / self.env.UAV_speed)\n",
    "                    #print(table_x, table_y)\n",
    "                    state_action_values[act] = state_action_values[act] + reward + self.gamma * old_table[table_x][table_y]   \n",
    "                state_value = np.max(state_action_values)\n",
    "                self.q_table[state_x][state_y] = state_value\n",
    "                #print(\"Update x: {}, y: {} to value {}\".format(state_x, state_y, state_value))\n",
    "            \n",
    "    def train(self):\n",
    "        old_state_value_table = self.copy_current_table()\n",
    "        current_step = 0\n",
    "        while current_step < self.config['max_iteration']:  \n",
    "            current_step = current_step + 1\n",
    "            self.update_value_function()\n",
    "            if current_step % self.config[\"evaluate_interval\"] == 0:\n",
    "                print(\"Iteration {}, Mean Reward is: {}\".format(current_step, evaluate(self.policy, config = self.config, num_episodes=1, render=False)))\n",
    "                #print(\"Iteration {}, Mean Reward is: {}\".format(current_step, 0))\n",
    "                # check exist\n",
    "                stop = True\n",
    "                flag = 0\n",
    "                for x in range(self.obs_dim[0] + 1):\n",
    "                    for y in range(self.obs_dim[1] + 1):\n",
    "                        if abs(self.q_table[x][y] - old_state_value_table[x][y]) > self.config[\"return_threshold\"]:\n",
    "                            stop = False\n",
    "                            flag = 1\n",
    "                    if flag == 1:\n",
    "                        break\n",
    "                if stop == True:\n",
    "                    print(\"Train converge at i = {}\".format(current_step))\n",
    "                    current_step = self.config['max_iteration']\n",
    "                else:\n",
    "                    old_state_value_table = self.copy_current_table()\n",
    "\n",
    "    def policy(self, obs):\n",
    "        table_x = int(obs[0] / self.env.UAV_speed)\n",
    "        table_y = int(obs[1] / self.env.UAV_speed)\n",
    "        next_state_value_list = []\n",
    "        for act in range(0, self.act_dim):\n",
    "            next_state, reward = self.get_transition((table_x, table_y), act)\n",
    "            next_state_x = int(next_state[0] / self.env.UAV_speed)\n",
    "            next_state_y = int(next_state[1] / self.env.UAV_speed)\n",
    "            next_state_value_list.append(self.q_table[next_state_x][next_state_y])\n",
    "        act = np.argmax(next_state_value_list)\n",
    "        return act, self.env.UAV_speed\n",
    "\n",
    "value_iteration_config = merge_config(dict(\n",
    "    max_iteration=10000,\n",
    "    evaluate_interval=100,  # don't need to update policy each iteration\n",
    "    map=dict(\n",
    "        width=1000,\n",
    "        length=1000,\n",
    "        height=100\n",
    "    ),\n",
    "    gamma=0.9,\n",
    "    return_threshold=1,\n",
    "    random_seed = 25,\n",
    "    is_random_env = False\n",
    "), environment_config)\n",
    "trainer = UAVTrainerValueIteration(value_iteration_config)\n",
    "trainer.env.print_locations()\n",
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action_space: (0, 1, 2, 3), total_steps: 50, current_step: 49, random_seed: 25, map: {'width': 1000, 'length': 1000, 'height': 100}, UAV_speed: 50, UAV_initial_pos: (0, 0), UAV_current_pos: (300, 50), number_of_user: 10, users_pos: [(386, 786), (949, 863), (863, 15), (219, 953), (892, 312), (651, 484), (43, 878), (975, 775), (261, 35), (313, 578)], UAV_path: [(0, 0), (50, 0), (100, 0), (150, 0), (200, 0), (200, 50), (250, 50), (250, 100), (300, 100), (300, 50), (300, 100), (300, 50), (300, 100), (300, 50), (300, 100), (300, 50), (300, 100), (300, 50), (300, 100), (300, 50), (300, 100), (300, 50), (300, 100), (300, 50), (300, 100), (300, 50), (300, 100), (300, 50), (300, 100), (300, 50), (300, 100), (300, 50), (300, 100), (300, 50), (300, 100), (300, 50), (300, 100), (300, 50), (300, 100), (300, 50), (300, 100), (300, 50), (300, 100), (300, 50), (300, 100), (300, 50), (300, 100), (300, 50), (300, 100)], g0: 1e-05, B: 1000000, Pk: 0.1, noise: 1e-09\n",
      "Current Step: 49\n",
      "Policy choice direction: 0, speed: 50\n",
      "UAV current position x: 300, y: 50\n",
      "Current step reward: 0.1440653703112022, episodes rewards: 6.197534975311915\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Reward is: 6.315389433958716\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean Reward is: {}\".format(evaluate(trainer.policy, config = value_iteration_config, num_episodes=1, render=True))) # Enable render=True can see the agent behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The rest is we try to create more complex environment, with more action space and state, not finished yet, please ignore the rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "\n",
    "class UAVEnvironmentComplex(UAVEnvironment):\n",
    "    \"\"\"\n",
    "    Complex UAV environment, action can be compose as (speed, direction), UAV position can be continous float number\n",
    "    \n",
    "    State = (self.UAV_current_pos, self.users_pos [list])\n",
    "    Action = (speed, direction)\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super(UAVEnvironmentComplex, self).__init__(config)\n",
    "        delattr(self, \"action_space\") \n",
    "\n",
    "\n",
    "    def transition_dynamics(self, action, state):\n",
    "        # action = (speed, direction), speed with 0 and self.UAV_speed, direction with (0, 2 * pi)\n",
    "        speed = action[0]\n",
    "        direction = action[1]\n",
    "        next_x = self.UAV_current_pos[0] + speed * math.cos(direction)\n",
    "        next_y = self.UAV_current_pos[1] + speed * math.sin(direction)\n",
    "        next_x = max(0, next_x)\n",
    "        next_x = min(self.map[\"width\"], next_x)\n",
    "        next_y = max(0, next_y)\n",
    "        next_y = min(self.map[\"length\"], next_y)\n",
    "        return (next_x, next_y)\n",
    "  \n",
    "\n",
    "    def reset(self):\n",
    "        self.current_step = 0\n",
    "        self.UAV_current_pos = self.UAV_initial_pos\n",
    "        return (self.UAV_current_pos, self.users_pos)\n",
    "    \n",
    "    def step(self, action):\n",
    "        # action = (speed, direction)\n",
    "        # This function return the state = (self.UAV_current_pos, self.users_pos [list])\n",
    "        speed = action[0]\n",
    "        speed = max(0, speed)\n",
    "        speed = min(self.UAV_speed, speed)\n",
    "        \n",
    "        standarded_action = (speed, action[1])\n",
    "        self.UAV_current_pos = self.transition_dynamics(standarded_action, self.UAV_current_pos)\n",
    "        self.current_step = self.current_step + 1\n",
    "        done = False\n",
    "        if self.current_step == self.total_steps:\n",
    "            done =  True\n",
    "        state = (self.UAV_current_pos, self.users_pos)\n",
    "        reward = self.get_reward(self.UAV_current_pos)\n",
    "        return state, reward, done\n",
    "    \n",
    "    def action_sample(self):\n",
    "        speed = random.uniform(0, 1) * self.UAV_speed\n",
    "        random_direction = math.pi * 2 * random.uniform(0, 1)\n",
    "        action = (speed, random_direction)\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UAV position is: (0, 0)\n",
      "Users position are: [(585, 33), (439, 494), (591, 15), (211, 473), (832, 503), (843, 284), (669, 830), (164, 35), (533, 501), (335, 77)]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "myGame = UAVEnvironmentComplex(environment_config)\n",
    "myGame.print_locations()\n",
    "myGame.print_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_complex(policy, config, num_episodes=1, render=False):\n",
    "    env = UAVEnvironmentComplex(config)\n",
    "    rewards = []\n",
    "    for i in range(num_episodes):\n",
    "        obs = env.reset()\n",
    "        # all policy will return a direction and a speed\n",
    "        action = policy(obs)\n",
    "        ep_reward = 0\n",
    "        while True:\n",
    "            obs, reward, done = env.step(action)\n",
    "            action = policy(obs)\n",
    "            ep_reward += reward\n",
    "            if done:\n",
    "                break\n",
    "            if render == True:\n",
    "                clear_output(wait=True)\n",
    "                env.print_locations()\n",
    "                print(\"Current Step: {}\".format(env.current_step))\n",
    "                print(\"Policy choice direction: {}, speed: {}\".format((action[1] * 180 / math.pi), action[0]))\n",
    "                print(\"Current step reward: {}, episodes rewards: {}\".format(reward, ep_reward))\n",
    "                env.print_map()\n",
    "                wait(sleep=0.2)\n",
    "        rewards.append(ep_reward)\n",
    "    return np.mean(rewards)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Class for all RL algorithm\n",
    "class UAVComplexTrainer: \n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.env = UAVEnvironmentComplex(self.config)\n",
    "            \n",
    "    def train(self):\n",
    "        pass\n",
    "    \n",
    "    def compute_values(self, state):\n",
    "        pass\n",
    "    \n",
    "    def state_to_feature_vector(self, UAV_pos, User_pos_list):\n",
    "        # State (UAV_pos, Users_pos), assmue there is max_number_of_user which UAV can be server, to define the feature vector length\n",
    "        # Feature vector: a vector contain tuple of positions\n",
    "        capacity = self.config[\"max_number_of_user\"] + 1 # UAV + user\n",
    "        features = [0] * capacity * 2\n",
    "        features[0] = UAV_pos[0]\n",
    "        features[1] = UAV_pos[1]\n",
    "        for i in range(0, len(User_pos_list)):\n",
    "            features[2*i+2] = User_pos_list[i][0]\n",
    "            features[2*i+3] = User_pos_list[i][1]\n",
    "        return features\n",
    "\n",
    "    def policy(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UAV position is: (51.01451578742905, 165.0454522954054)\n",
      "Users position are: [(585, 33), (439, 494), (591, 15), (211, 473), (832, 503), (843, 284), (669, 830), (164, 35), (533, 501), (335, 77)]\n",
      "Current Step: 49\n",
      "Policy choice direction: 174.61992628982568, speed: 49.63440328818769\n",
      "Current step reward: 0.08588896539071643, episodes rewards: 5.534714770145497\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Reward is: 5.603205868217308\n"
     ]
    }
   ],
   "source": [
    "# Start from random policy\n",
    "class UAVComplexTrainerRandomPolicy(UAVComplexTrainer):\n",
    "    def __init__(self, config):\n",
    "        super(UAVComplexTrainerRandomPolicy, self).__init__(config)\n",
    "        \n",
    "    def policy(self, obs):\n",
    "        action = self.env.action_sample()\n",
    "        return action\n",
    "\n",
    "random_policy_config = environment_config\n",
    "trainer = UAVComplexTrainerRandomPolicy(random_policy_config)\n",
    "print(\"Mean Reward is: {}\".format(evaluate_complex(trainer.policy, config = random_policy_config, num_episodes=1, render=True))) # Enable render=True can see the agent behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "def to_tensor(x):\n",
    "    \"\"\"A helper function to transform a numpy array to a Pytorch Tensor\"\"\"\n",
    "    if isinstance(x, list):\n",
    "        x = np.array(x) \n",
    "    if isinstance(x, np.ndarray):\n",
    "        x = torch.from_numpy(x).type(torch.float32)\n",
    "    assert isinstance(x, torch.Tensor)\n",
    "    return x\n",
    "\n",
    "\n",
    "class NetworkModel(nn.Module):\n",
    "    def __init__(self, obs_dim, act_dim):\n",
    "        super(NetworkModel, self).__init__()\n",
    "        self.network = torch.nn.Sequential(\n",
    "            torch.nn.Linear(obs_dim,100),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(100,100),\n",
    "            torch.nn.ReLU(),\n",
    "            torch.nn.Linear(100,act_dim),\n",
    "        )\n",
    "\n",
    "    def forward(self, obs):\n",
    "        return self.network(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Class for all RL algorithm\n",
    "class UAVComplexTrainerNN(UAVComplexTrainer): \n",
    "    def __init__(self, config):\n",
    "        super(UAVComplexTrainerNN, self).__init__(config)\n",
    "        self.max_episode_length = self.config[\"max_episode_length\"]\n",
    "        self.learning_rate = self.config[\"learning_rate\"]\n",
    "        self.gamma = self.config[\"gamma\"]\n",
    "        self.model = NetworkModel((self.config[\"max_number_of_user\"] + 1) * 2, 2)\n",
    "\n",
    "    def train(self):\n",
    "        pass\n",
    "    \n",
    "    def policy(self, state):\n",
    "        if np.random.uniform(0,1) <= self.config[\"eps\"]:\n",
    "            action = self.env.action_sample()\n",
    "        else:\n",
    "            feature = self.state_to_feature_vector(state[0], state[1])\n",
    "            model_input = to_tensor(feature).squeeze()\n",
    "            action = self.model(model_input)\n",
    "        return action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UAV position is: (0, 18.18020392459561)\n",
      "Users position are: [(847, 534), (739, 433), (458, 680), (761, 568), (213, 272), (611, 373), (118, 642), (801, 642), (7, 214), (434, 624)]\n",
      "Current Step: 49\n",
      "Policy choice direction: -1619.9998779296875, speed: 91.45848846435547\n",
      "Current step reward: 0.05899476939196227, episodes rewards: 2.886871512090615\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Reward is: 2.9458662819386667\n"
     ]
    }
   ],
   "source": [
    "linear_function_config = merge_config(dict(\n",
    "    total_steps = 50,\n",
    "    number_of_user = 10,\n",
    "    max_number_of_user = 20,\n",
    "    map=dict(\n",
    "        width=1000,\n",
    "        length=1000,\n",
    "        height=100\n",
    "    ),\n",
    "    max_episode_length=10000,\n",
    "    eps=0.01,\n",
    "    gamma=0.9,\n",
    "    parameter_std=0.01,\n",
    "    learning_rate=0.01,\n",
    "), environment_config)\n",
    "\n",
    "NNTrainer = UAVComplexTrainerNN(linear_function_config)\n",
    "print(\"Mean Reward is: {}\".format(evaluate_complex(NNTrainer.policy, config = linear_function_config, num_episodes=1, render=True))) # Enable render=True can see the agent behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, sigma = 0, 0.1 # mean and standard deviation\n",
    "s = np.random.normal(mu, sigma, (10,3))\n",
    "print(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
