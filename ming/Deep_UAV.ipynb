{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "from random import randint, choice\n",
    "import matplotlib.pyplot as plt\n",
    "from util import *\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UAVEnvironment:\n",
    "    \"\"\"\n",
    "    Game environment for UAV test\n",
    "    \n",
    "    ---Map---\n",
    "    \n",
    "    y-axis(length)\n",
    "    |\n",
    "    |\n",
    "    |\n",
    "    |\n",
    "    |\n",
    "    |\n",
    "     _______________________ x-axis(width)\n",
    "     \n",
    "    Hight is a fixed value\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        # Game config\n",
    "        self.action_space = (1, 2, 3, 4) # up, right, down, left, total 4 actions\n",
    "        self.total_steps = config[\"total_steps\"] # when the game end\n",
    "        self.current_step = 0\n",
    "        \n",
    "        # Map config\n",
    "        self.map = dict(width=config[\"map\"][\"width\"], length=config[\"map\"][\"length\"], height=config[\"map\"][\"height\"])\n",
    "        self.UAV_speed = config[\"UAV_speed\"]\n",
    "        self.UAV_initial_pos = config[\"UAV_initial_pos\"] # a tuple\n",
    "        self.UAV_current_pos = self.UAV_initial_pos\n",
    "        self.number_of_user = config[\"number_of_user\"]\n",
    "        self.users_pos = list()\n",
    "        for i in range(0, self.number_of_user):\n",
    "            self.users_pos.append((randint(0, self.map[\"width\"]), randint(0, self.map[\"length\"])))\n",
    "        \n",
    "        # Wireless config\n",
    "        self.g0 = config[\"wireless_parameter\"][\"g0\"]\n",
    "        self.B = config[\"wireless_parameter\"][\"B\"]\n",
    "        self.Pk = config[\"wireless_parameter\"][\"Pk\"]\n",
    "        self.noise = config[\"wireless_parameter\"][\"noise\"]\n",
    "        \n",
    "    def get_reward(self):\n",
    "        # One step Reward is define as the summation of all user's utility\n",
    "        reward = 0\n",
    "        for user_index in range(0, self.number_of_user):\n",
    "            gkm = self.g0 / (self.map[\"height\"] ** 2 + (self.UAV_current_pos[0] - self.users_pos[user_index][0]) ** 2 + (self.UAV_current_pos[1] - self.users_pos[user_index][1]) ** 2)\n",
    "            user_utility = self.B * math.log(1 + self.Pk * gkm / self.noise, 2)\n",
    "            reward = reward + user_utility\n",
    "        return reward\n",
    "    \n",
    "    def transition_dynamics(self, action, speed):\n",
    "        # given the action (direction), calculate the next state (UAV current position)\n",
    "        assert action in self.action_space\n",
    "        next_UAV_pos = list(self.UAV_current_pos)\n",
    "        if action == 1:\n",
    "            # move up\n",
    "            next_UAV_pos[1] = min(next_UAV_pos[1] + speed, self.map[\"length\"])\n",
    "        if action == 2:\n",
    "            # move right\n",
    "            next_UAV_pos[0] = min(next_UAV_pos[0] + speed, self.map[\"width\"])\n",
    "        if action == 3:\n",
    "            # move down\n",
    "            next_UAV_pos[1] = max(next_UAV_pos[1] - speed, 0)\n",
    "        if action == 4:\n",
    "            # move left\n",
    "            next_UAV_pos[0] = max(next_UAV_pos[0] - speed, 0)\n",
    "        return tuple(next_UAV_pos)\n",
    "    \n",
    "    def step(self, action, speed=-1):\n",
    "        # assume we use the max speed as the default speed, when come near to the opt-position, we can slow down the speed\n",
    "        if speed < 0 or speed >= self.UAV_speed:\n",
    "            speed = self.UAV_speed\n",
    "            \n",
    "        self.UAV_current_pos = self.transition_dynamics(action, speed)\n",
    "        self.current_step = self.current_step + 1\n",
    "        done = False\n",
    "        if self.current_step == self.total_steps:\n",
    "            done =  True\n",
    "        return self.UAV_current_pos, self.get_reward(), done\n",
    "    \n",
    "    def action_sample(self):\n",
    "        return choice(self.action_space)\n",
    "    \n",
    "    def reset(self):\n",
    "        self.current_step = 0\n",
    "        self.UAV_current_pos = self.UAV_initial_pos\n",
    "        self.users_pos = list()\n",
    "        for i in range(0, self.number_of_user):\n",
    "            self.users_pos.append((randint(0, self.map[\"width\"]), randint(0, self.map[\"length\"])))\n",
    "        \n",
    "    def print_attribute(self):\n",
    "        attrs = vars(self)\n",
    "        print(', '.join(\"%s: %s\" % item for item in attrs.items()))\n",
    "        \n",
    "    def print_map(self):\n",
    "        x_list = [pos[0] for pos in self.users_pos]\n",
    "        y_list = [pos[1] for pos in self.users_pos]\n",
    "        x_list.append(self.UAV_current_pos[0])\n",
    "        y_list.append(self.UAV_current_pos[1])\n",
    "        \n",
    "        colors = np.array([\"red\", \"green\"])\n",
    "        sizes = []\n",
    "        colors_map = []\n",
    "        for i in range(0, self.number_of_user):\n",
    "            sizes.append(25)\n",
    "            colors_map.append(1)\n",
    "        sizes.append(50)\n",
    "        colors_map.append(0)\n",
    "        plt.scatter(x_list, y_list, c=colors[colors_map], s=sizes) \n",
    "        plt.axis([0, self.map[\"width\"], 0, self.map[\"length\"]])\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment_config = dict(\n",
    "    total_steps = 50,\n",
    "    map=dict(\n",
    "        width=1000,\n",
    "        length=1000,\n",
    "        height=100\n",
    "    ),\n",
    "    number_of_user = 10,\n",
    "    UAV_speed = 20,\n",
    "    UAV_initial_pos = (500, 500),\n",
    "    wireless_parameter = dict(\n",
    "        g0 = 10 ** (-5),\n",
    "        B = 10 ** (6),\n",
    "        Pk = 0.1,\n",
    "        noise = 10 ** (-9)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action_space: (1, 2, 3, 4), total_steps: 50, current_step: 0, map: {'width': 1000, 'length': 1000, 'height': 100}, UAV_speed: 20, UAV_initial_pos: (500, 500), UAV_current_pos: (500, 500), number_of_user: 10, users_pos: [(913, 3), (206, 526), (126, 186), (505, 593), (376, 256), (8, 511), (444, 483), (830, 312), (888, 919), (825, 670)], g0: 1e-05, B: 1000000, Pk: 0.1, noise: 1e-09\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "myGame = UAVEnvironment(environment_config)\n",
    "myGame.print_attribute()\n",
    "myGame.print_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(policy, num_episodes=1, render=False):\n",
    "    env = UAVEnvironment(environment_config)\n",
    "    rewards = []\n",
    "    for i in range(num_episodes):\n",
    "        obs = env.reset()\n",
    "        # all policy will return a direction and a speed\n",
    "        act_direction, act_speed = policy(obs)\n",
    "        ep_reward = 0\n",
    "        while True:\n",
    "            obs, reward, done = env.step(act_direction, act_speed)\n",
    "            act_direction, act_speed = policy(obs)\n",
    "            ep_reward += reward\n",
    "            if done:\n",
    "                break\n",
    "            if render:\n",
    "                clear_output(wait=True)\n",
    "                print(\"Current Step: {}\".format(env.current_step))\n",
    "                print(\"Policy choice direction: {}, speed: {}\".format(act_direction, act_speed))\n",
    "                print(\"UAV current position x: {}, y: {}\".format(env.UAV_current_pos[0], env.UAV_current_pos[1]))\n",
    "                print(\"Current step reward: {}, episodes rewards: {}\".format(reward, ep_reward))\n",
    "                env.print_map()\n",
    "                wait(sleep=0.5)\n",
    "        rewards.append(ep_reward)\n",
    "    return np.mean(rewards)\n",
    "\n",
    "\n",
    "def run(trainer_cls, config=None, reward_threshold=None):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UAVTrainer:\n",
    "    # Basic Class for all RL algorithm\n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.env = UAVEnvironment(self.config)\n",
    "        \n",
    "    def compute_values(self, processed_state):\n",
    "        pass\n",
    "    \n",
    "    def compute_action(self, processed_state):\n",
    "        pass\n",
    "    \n",
    "    def train(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UAVTrainerRandomPolicy(UAVTrainer):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        \n",
    "    def policy(self, obs):\n",
    "        max_speed = self.env.UAV_speed\n",
    "        return self.env.action_sample(), max_speed\n",
    "        #return 4, max_speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_policy_config = environment_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Reward is: 11462230.33966036\n"
     ]
    }
   ],
   "source": [
    "trainer = UAVTrainerRandomPolicy(random_policy_config)\n",
    "print(\"Mean Reward is: {}\".format(evaluate(trainer.policy, num_episodes=1, render=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
