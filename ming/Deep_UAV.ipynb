{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "import random\n",
    "from random import randint, choice\n",
    "import matplotlib.pyplot as plt\n",
    "from util import *\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 516,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UAVEnvironment:\n",
    "    \"\"\"\n",
    "    Game environment for UAV test\n",
    "    \n",
    "    ---Map---\n",
    "    \n",
    "    y-axis(length)\n",
    "    |\n",
    "    |\n",
    "    |\n",
    "    |\n",
    "    |\n",
    "    |\n",
    "     _______________________ x-axis(width)\n",
    "     \n",
    "    Hight is a fixed value\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        # Game config\n",
    "        self.action_space = (0, 1, 2, 3) # up, right, down, left, total 4 actions\n",
    "        self.total_steps = config[\"total_steps\"] # when the game end\n",
    "        self.current_step = 0\n",
    "        if config[\"is_random_env\"] == False:\n",
    "            self.random_seed = config[\"random_seed\"]\n",
    "            random.seed(self.random_seed)\n",
    "        \n",
    "        # Map config\n",
    "        self.map = dict(width=config[\"map\"][\"width\"], length=config[\"map\"][\"length\"], height=config[\"map\"][\"height\"])\n",
    "        self.UAV_speed = config[\"UAV_speed\"]\n",
    "        self.UAV_initial_pos = config[\"UAV_initial_pos\"] # a tuple\n",
    "        self.UAV_current_pos = self.UAV_initial_pos\n",
    "        self.number_of_user = config[\"number_of_user\"]\n",
    "        self.users_pos = list()\n",
    "        for i in range(0, self.number_of_user):\n",
    "            self.users_pos.append((randint(0, self.map[\"width\"]), randint(0, self.map[\"length\"])))\n",
    "        \n",
    "        # Wireless config\n",
    "        self.g0 = config[\"wireless_parameter\"][\"g0\"]\n",
    "        self.B = config[\"wireless_parameter\"][\"B\"]\n",
    "        self.Pk = config[\"wireless_parameter\"][\"Pk\"]\n",
    "        self.noise = config[\"wireless_parameter\"][\"noise\"]\n",
    "        \n",
    "    def get_reward(self, UAV_pos):\n",
    "        # One step Reward is define as the summation of all user's utility\n",
    "        reward = 0\n",
    "        for user_index in range(0, self.number_of_user):\n",
    "            gkm = self.g0 / (self.map[\"height\"] ** 2 + (UAV_pos[0] - self.users_pos[user_index][0]) ** 2 + (UAV_pos[1] - self.users_pos[user_index][1]) ** 2)\n",
    "            user_utility = self.B * math.log(1 + self.Pk * gkm / self.noise, 2)\n",
    "            reward = reward + user_utility\n",
    "        return reward / (10 ** 6) # Use Mkbps as signal basic unit\n",
    "    \n",
    "    def transition_dynamics(self, action, speed, state):\n",
    "        # given the action (direction), calculate the next state (UAV current position)\n",
    "        assert action in self.action_space\n",
    "        next_UAV_pos = list(state)\n",
    "        if action == 0:\n",
    "            # move up\n",
    "            next_UAV_pos[1] = min(next_UAV_pos[1] + speed, self.map[\"length\"])\n",
    "        if action == 1:\n",
    "            # move right\n",
    "            next_UAV_pos[0] = min(next_UAV_pos[0] + speed, self.map[\"width\"])\n",
    "        if action == 2:\n",
    "            # move down\n",
    "            next_UAV_pos[1] = max(next_UAV_pos[1] - speed, 0)\n",
    "        if action == 3:\n",
    "            # move left\n",
    "            next_UAV_pos[0] = max(next_UAV_pos[0] - speed, 0)\n",
    "        return tuple(next_UAV_pos)\n",
    "    \n",
    "    def get_transition(self):\n",
    "        # This function only works for model based, we are trying to disable this function to try more algorithm\n",
    "        # Return a table of transition, we assume UAV use fixed flying speed\n",
    "        \"\"\"\n",
    "        Structure:\n",
    "        transition[\n",
    "            x_0[\n",
    "                y_0[\n",
    "                    {next_state, reward}, # for action 1\n",
    "                    {next_state, reward}, # for action 2\n",
    "                    ...\n",
    "                    {next_state, reward}, # for action 20\n",
    "                ],\n",
    "                y_1*v[],\n",
    "                ...\n",
    "                y_h-1*v[]\n",
    "            ],\n",
    "            x_1*v[],\n",
    "            x_2*v[],\n",
    "            ...\n",
    "            x_w-1*v[]\n",
    "        ]\n",
    "        \n",
    "        \"\"\"\n",
    "        transition = list()\n",
    "        for state_x in range(0, int(self.map[\"width\"] / self.UAV_speed) + 1):\n",
    "            transition.append(list())\n",
    "            for state_y in range(0, int(self.map[\"length\"] / self.UAV_speed) + 1):\n",
    "                transition[state_x].append(list())\n",
    "                for action in self.action_space:\n",
    "                    next_state = self.transition_dynamics(action, self.UAV_speed, (state_x * self.UAV_speed, state_y * self.UAV_speed))\n",
    "                    reward = self.get_reward(next_state)\n",
    "                    transition[state_x][state_y].append(dict(next_state=next_state,reward=reward))\n",
    "        return transition\n",
    "                    \n",
    "    def step(self, action, speed=-1):\n",
    "        # assume we use the max speed as the default speed, when come near to the opt-position, we can slow down the speed\n",
    "        if speed < 0 or speed >= self.UAV_speed:\n",
    "            speed = self.UAV_speed\n",
    "            \n",
    "        self.UAV_current_pos = self.transition_dynamics(action, speed, self.UAV_current_pos)\n",
    "        self.current_step = self.current_step + 1\n",
    "        done = False\n",
    "        if self.current_step == self.total_steps:\n",
    "            done =  True\n",
    "        return self.UAV_current_pos, self.get_reward(self.UAV_current_pos), done\n",
    "    \n",
    "    def action_sample(self):\n",
    "        return choice(self.action_space)\n",
    "    \n",
    "    def reset(self):\n",
    "        self.current_step = 0\n",
    "        self.UAV_current_pos = self.UAV_initial_pos\n",
    "        #self.users_pos = list()\n",
    "        #for i in range(0, self.number_of_user):\n",
    "        #    self.users_pos.append((randint(0, self.map[\"width\"]), randint(0, self.map[\"length\"])))\n",
    "        return self.UAV_current_pos\n",
    "        \n",
    "    def print_attribute(self):\n",
    "        attrs = vars(self)\n",
    "        print(', '.join(\"%s: %s\" % item for item in attrs.items()))\n",
    "        \n",
    "    def print_map(self):\n",
    "        x_list = [pos[0] for pos in self.users_pos]\n",
    "        y_list = [pos[1] for pos in self.users_pos]\n",
    "        x_list.append(self.UAV_current_pos[0])\n",
    "        y_list.append(self.UAV_current_pos[1])\n",
    "        \n",
    "        colors = np.array([\"red\", \"green\"])\n",
    "        sizes = []\n",
    "        colors_map = []\n",
    "        for i in range(0, self.number_of_user):\n",
    "            sizes.append(25)\n",
    "            colors_map.append(1)\n",
    "        sizes.append(50)\n",
    "        colors_map.append(0)\n",
    "        plt.scatter(x_list, y_list, c=colors[colors_map], s=sizes) \n",
    "        plt.axis([0, self.map[\"width\"], 0, self.map[\"length\"]])\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 517,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment_config = dict(\n",
    "    total_steps = 10,\n",
    "    random_seed = 0,\n",
    "    is_random_env = False,\n",
    "    map=dict(\n",
    "        width=1000,\n",
    "        length=1000,\n",
    "        height=100\n",
    "    ),\n",
    "    number_of_user = 10,\n",
    "    UAV_speed = 20,\n",
    "    UAV_initial_pos = (0, 0),\n",
    "    wireless_parameter = dict(\n",
    "        g0 = 10 ** (-5),\n",
    "        B = 10 ** (6),\n",
    "        Pk = 0.1,\n",
    "        noise = 10 ** (-9)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 519,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action_space: (0, 1, 2, 3), total_steps: 10, current_step: 0, random_seed: 0, map: {'width': 1000, 'length': 1000, 'height': 100}, UAV_speed: 20, UAV_initial_pos: (0, 0), UAV_current_pos: (0, 0), number_of_user: 10, users_pos: [(864, 394), (776, 911), (430, 41), (265, 988), (523, 497), (414, 940), (802, 849), (310, 991), (488, 366), (597, 913)], g0: 1e-05, B: 1000000, Pk: 0.1, noise: 1e-09\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "myGame = UAVEnvironment(environment_config)\n",
    "myGame.print_attribute()\n",
    "myGame.print_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(policy, config, num_episodes=1, render=False):\n",
    "    env = UAVEnvironment(config)\n",
    "    \n",
    "    rewards = []\n",
    "    for i in range(num_episodes):\n",
    "        obs = env.reset()\n",
    "        # all policy will return a direction and a speed\n",
    "        act_direction, act_speed = policy(obs)\n",
    "        ep_reward = 0\n",
    "        while True:\n",
    "            obs, reward, done = env.step(act_direction, act_speed)\n",
    "            act_direction, act_speed = policy(obs)\n",
    "            ep_reward += reward\n",
    "            if done:\n",
    "                break\n",
    "            if render = True:\n",
    "                clear_output(wait=True)\n",
    "                env.print_attribute()\n",
    "                print(\"Current Step: {}\".format(env.current_step))\n",
    "                print(\"Policy choice direction: {}, speed: {}\".format(act_direction, act_speed))\n",
    "                print(\"UAV current position x: {}, y: {}\".format(env.UAV_current_pos[0], env.UAV_current_pos[1]))\n",
    "                print(\"Current step reward: {}, episodes rewards: {}\".format(reward, ep_reward))\n",
    "                env.print_map()\n",
    "                wait(sleep=0.2)\n",
    "        rewards.append(ep_reward)\n",
    "    return np.mean(rewards)\n",
    "\n",
    "def run(trainer_cls, config=None, reward_threshold=None):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Class for all RL algorithm\n",
    "class UAVTrainer: \n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.env = UAVEnvironment(self.config)\n",
    "    \n",
    "    def train(self):\n",
    "        pass\n",
    "    \n",
    "    def policy(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 495,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action_space: (0, 1, 2, 3), total_steps: 10, current_step: 0, random_seed: 0, map: {'width': 120, 'length': 60, 'height': 100}, UAV_speed: 20, UAV_initial_pos: (0, 0), UAV_current_pos: (0, 0), number_of_user: 1, users_pos: [(108, 24)], g0: 1e-05, B: 1000000, Pk: 0.1, noise: 1e-09\n",
      "Mean Reward is: 0.6778269285353753\n"
     ]
    }
   ],
   "source": [
    "# Start from random policy\n",
    "class UAVTrainerRandomPolicy(UAVTrainer):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        \n",
    "    def policy(self, obs):\n",
    "        max_speed = self.env.UAV_speed\n",
    "        return self.env.action_sample(), max_speed\n",
    "\n",
    "random_policy_config = environment_config\n",
    "trainer = UAVTrainerRandomPolicy(random_policy_config)\n",
    "trainer.env.print_attribute()\n",
    "print(\"Mean Reward is: {}\".format(evaluate(trainer.policy, config = random_policy_config, num_episodes=1, render=False))) # Enable render=True can see the agent behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 526,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action_space: (0, 1, 2, 3), total_steps: 50, current_step: 0, random_seed: 10, map: {'width': 1000, 'length': 1000, 'height': 10000}, UAV_speed: 20, UAV_initial_pos: (0, 0), UAV_current_pos: (0, 0), number_of_user: 10, users_pos: [(585, 33), (439, 494), (591, 15), (211, 473), (832, 503), (843, 284), (669, 830), (164, 35), (533, 501), (335, 77)], g0: 1e-05, B: 1000000, Pk: 0.1, noise: 1e-09\n",
      "Iteration 100, Mean Reward is: 0.007197806641099489\n",
      "Train converge at i = 100\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "# Value Iteration, Tabular, transition dynamic is known, assume only use fixed speed to reduce action space\n",
    "class UAVTrainerValueIteration(UAVTrainer):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.config = config\n",
    "        self.transitions = self.env.get_transition()\n",
    "        self.q_table = []\n",
    "        self.obs_dim = (int(self.env.map[\"width\"] / self.env.UAV_speed), int(self.env.map[\"length\"] / self.env.UAV_speed))\n",
    "        self.act_dim = len(self.env.action_space)\n",
    "        self.gamma = config[\"gamma\"]\n",
    "        \n",
    "        for x in range(0, self.obs_dim[0]+1):\n",
    "            self.q_table.append(list())\n",
    "            for y in range(0, self.obs_dim[1]+1):\n",
    "                self.q_table[x].append(0)\n",
    "            \n",
    "    def get_transition(self, state, act):\n",
    "        transition = self.transitions[state[0]][state[1]][act]\n",
    "        return transition[\"next_state\"], transition[\"reward\"]\n",
    "    \n",
    "    def print_transitions(self):\n",
    "        print(\"Transition width {}, length {}, number of act {}\".format(len(self.transitions), len(self.transitions[0]), len(self.transitions[0][0])))\n",
    "        print(self.transitions)\n",
    "        \n",
    "    def print_table(self):\n",
    "        for j in range(len(self.q_table[0])-1, -1, -1):\n",
    "            for i in range(0, len(self.q_table)):\n",
    "                print(self.q_table[i][j], end =\" \")\n",
    "            print(\"\")\n",
    "            \n",
    "            \n",
    "    def copy_current_table(self):\n",
    "        old_table = []\n",
    "        for x in range(0, self.obs_dim[0]+1):\n",
    "            old_table.append(list())\n",
    "            for y in range(0, self.obs_dim[1]+1):\n",
    "                old_table[x].append(self.q_table[x][y])\n",
    "        return old_table\n",
    "\n",
    "    def update_value_function(self):\n",
    "        old_table = self.copy_current_table()\n",
    "        for state_x in range(self.obs_dim[0] + 1):\n",
    "            for state_y in range(self.obs_dim[1] + 1):\n",
    "                state_value = 0\n",
    "                state_action_values = [0 for i in range(0, self.act_dim)]\n",
    "\n",
    "                for act in range(self.act_dim):\n",
    "                    next_state, reward = self.get_transition((state_x, state_y), act)\n",
    "                    table_x = int(next_state[0] / self.env.UAV_speed)\n",
    "                    table_y = int(next_state[1] / self.env.UAV_speed)\n",
    "                    #print(table_x, table_y)\n",
    "                    state_action_values[act] = state_action_values[act] + reward + self.gamma * old_table[table_x][table_y]   \n",
    "                state_value = np.max(state_action_values)\n",
    "                self.q_table[state_x][state_y] = state_value\n",
    "                #print(\"Update x: {}, y: {} to value {}\".format(state_x, state_y, state_value))\n",
    "            \n",
    "    def train(self):\n",
    "        old_state_value_table = self.copy_current_table()\n",
    "        current_step = 0\n",
    "        while current_step < self.config['max_iteration']:  \n",
    "            current_step = current_step + 1\n",
    "            self.update_value_function()\n",
    "            if current_step % self.config[\"evaluate_interval\"] == 0:\n",
    "                print(\"Iteration {}, Mean Reward is: {}\".format(current_step, evaluate(self.policy, config = self.config, num_episodes=1, render=False)))\n",
    "                #print(\"Iteration {}, Mean Reward is: {}\".format(current_step, 0))\n",
    "                # check exist\n",
    "                stop = True\n",
    "                flag = 0\n",
    "                for x in range(self.obs_dim[0] + 1):\n",
    "                    for y in range(self.obs_dim[1] + 1):\n",
    "                        if abs(self.q_table[x][y] - old_state_value_table[x][y]) > self.config[\"return_threshold\"]:\n",
    "                            stop = False\n",
    "                            flag = 1\n",
    "                    if flag == 1:\n",
    "                        break\n",
    "                if stop == True:\n",
    "                    print(\"Train converge at i = {}\".format(current_step))\n",
    "                    current_step = self.config['max_iteration']\n",
    "                else:\n",
    "                    old_state_value_table = self.copy_current_table()\n",
    "\n",
    "    def policy(self, obs):\n",
    "        table_x = int(obs[0] / self.env.UAV_speed)\n",
    "        table_y = int(obs[1] / self.env.UAV_speed)\n",
    "        next_state_value_list = []\n",
    "        for act in range(0, self.act_dim):\n",
    "            next_state, reward = self.get_transition((table_x, table_y), act)\n",
    "            next_state_x = int(next_state[0] / self.env.UAV_speed)\n",
    "            next_state_y = int(next_state[1] / self.env.UAV_speed)\n",
    "            next_state_value_list.append(self.q_table[next_state_x][next_state_y])\n",
    "        #print(next_state_value_list, act)\n",
    "        act = np.argmax(next_state_value_list)\n",
    "        return act, self.env.UAV_speed\n",
    "\n",
    "value_iteration_config = merge_config(dict(\n",
    "    max_iteration=10000,\n",
    "    total_steps = 50,\n",
    "    number_of_user = 10,\n",
    "    map=dict(\n",
    "        width=1000,\n",
    "        length=1000,\n",
    "        height=10000\n",
    "    ),\n",
    "    evaluate_interval=100,  # don't need to update policy each iteration\n",
    "    gamma=0.9,\n",
    "    return_threshold=1,\n",
    "    random_seed = 10,\n",
    "    is_random_env = False\n",
    "), environment_config)\n",
    "trainer = UAVTrainerValueIteration(value_iteration_config)\n",
    "trainer.env.print_attribute()\n",
    "#trainer.print_transitions()\n",
    "trainer.train()\n",
    "#trainer.print_table()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 527,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action_space: (0, 1, 2, 3), total_steps: 50, current_step: 49, random_seed: 10, map: {'width': 1000, 'length': 1000, 'height': 10000}, UAV_speed: 20, UAV_initial_pos: (0, 0), UAV_current_pos: (520, 340), number_of_user: 10, users_pos: [(585, 33), (439, 494), (591, 15), (211, 473), (832, 503), (843, 284), (669, 830), (164, 35), (533, 501), (335, 77)], g0: 1e-05, B: 1000000, Pk: 0.1, noise: 1e-09\n",
      "Current Step: 49\n",
      "Policy choice direction: 0, speed: 20\n",
      "UAV current position x: 520, y: 340\n",
      "Current step reward: 0.00014409658377021337, episodes rewards: 0.007053711526565199\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Reward is: 0.007197806641099489\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean Reward is: {}\".format(evaluate(trainer.policy, config = value_iteration_config, num_episodes=1, render=True))) # Enable render=True can see the agent behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random number with seed 30\n",
      "first -  37\n",
      "Second -  49\n",
      "Third -  37\n",
      "Third -  49\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "print (\"Random number with seed 30\")\n",
    "random.seed(0)\n",
    "print (\"first - \", random.randint(25,50))\n",
    "\n",
    "#will generate a same random number as previous\n",
    "print (\"Second - \", random.randint(25,50))\n",
    "\n",
    "#will generate a same random number as previous\n",
    "random.seed(0)\n",
    "print (\"Third - \", random.randint(25,50))\n",
    "print (\"Third - \", random.randint(25,50))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
