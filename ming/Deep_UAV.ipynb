{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 541,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import math\n",
    "import random\n",
    "from random import randint, choice\n",
    "import matplotlib.pyplot as plt\n",
    "from util import *\n",
    "from IPython.display import clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [],
   "source": [
    "class UAVEnvironment():\n",
    "    \"\"\"\n",
    "    Game environment for UAV test\n",
    "    \n",
    "    ---Map---\n",
    "    \n",
    "    y-axis(length)\n",
    "    |\n",
    "    |\n",
    "    |\n",
    "    |\n",
    "    |\n",
    "    |\n",
    "     _______________________ x-axis(width)\n",
    "     \n",
    "    Hight is a fixed value\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        # Game config\n",
    "        self.action_space = (0, 1, 2, 3) # up, right, down, left, total 4 actions\n",
    "        self.total_steps = config[\"total_steps\"] # when the game end\n",
    "        self.current_step = 0\n",
    "        if config[\"is_random_env\"] == False:\n",
    "            self.random_seed = config[\"random_seed\"]\n",
    "            random.seed(self.random_seed)\n",
    "        \n",
    "        # Map config\n",
    "        self.map = dict(width=config[\"map\"][\"width\"], length=config[\"map\"][\"length\"], height=config[\"map\"][\"height\"])\n",
    "        self.UAV_speed = config[\"UAV_speed\"]\n",
    "        self.UAV_initial_pos = config[\"UAV_initial_pos\"] # a tuple\n",
    "        self.UAV_current_pos = self.UAV_initial_pos\n",
    "        self.number_of_user = config[\"number_of_user\"]\n",
    "        self.users_pos = list()\n",
    "        for i in range(0, self.number_of_user):\n",
    "            self.users_pos.append((randint(0, self.map[\"width\"]), randint(0, self.map[\"length\"])))\n",
    "        \n",
    "        # Wireless config\n",
    "        self.g0 = config[\"wireless_parameter\"][\"g0\"]\n",
    "        self.B = config[\"wireless_parameter\"][\"B\"]\n",
    "        self.Pk = config[\"wireless_parameter\"][\"Pk\"]\n",
    "        self.noise = config[\"wireless_parameter\"][\"noise\"]\n",
    "        \n",
    "    def get_reward(self, UAV_pos):\n",
    "        # One step Reward is define as the summation of all user's utility\n",
    "        reward = 0\n",
    "        for user_index in range(0, self.number_of_user):\n",
    "            gkm = self.g0 / (self.map[\"height\"] ** 2 + (UAV_pos[0] - self.users_pos[user_index][0]) ** 2 + (UAV_pos[1] - self.users_pos[user_index][1]) ** 2)\n",
    "            user_utility = self.B * math.log(1 + self.Pk * gkm / self.noise, 2)\n",
    "            reward = reward + user_utility\n",
    "        return reward / (10 ** 6) # Use Mkbps as signal basic unit\n",
    "    \n",
    "    def transition_dynamics(self, action, speed, state):\n",
    "        # given the action (direction), calculate the next state (UAV current position)\n",
    "        assert action in self.action_space\n",
    "        next_UAV_pos = list(state)\n",
    "        if action == 0:\n",
    "            # move up\n",
    "            next_UAV_pos[1] = min(next_UAV_pos[1] + speed, self.map[\"length\"])\n",
    "        if action == 1:\n",
    "            # move right\n",
    "            next_UAV_pos[0] = min(next_UAV_pos[0] + speed, self.map[\"width\"])\n",
    "        if action == 2:\n",
    "            # move down\n",
    "            next_UAV_pos[1] = max(next_UAV_pos[1] - speed, 0)\n",
    "        if action == 3:\n",
    "            # move left\n",
    "            next_UAV_pos[0] = max(next_UAV_pos[0] - speed, 0)\n",
    "        return tuple(next_UAV_pos)\n",
    "    \n",
    "    def get_transition(self):\n",
    "        # This function only works for model based, we are trying to disable this function to try more algorithm\n",
    "        # Return a table of transition, we assume UAV use fixed flying speed\n",
    "        \"\"\"\n",
    "        Structure:\n",
    "        transition[\n",
    "            x_0[\n",
    "                y_0[\n",
    "                    {next_state, reward}, # for action 1\n",
    "                    {next_state, reward}, # for action 2\n",
    "                    ...\n",
    "                    {next_state, reward}, # for action 20\n",
    "                ],\n",
    "                y_1*v[],\n",
    "                ...\n",
    "                y_h-1*v[]\n",
    "            ],\n",
    "            x_1*v[],\n",
    "            x_2*v[],\n",
    "            ...\n",
    "            x_w-1*v[]\n",
    "        ]\n",
    "        \n",
    "        \"\"\"\n",
    "        transition = list()\n",
    "        for state_x in range(0, int(self.map[\"width\"] / self.UAV_speed) + 1):\n",
    "            transition.append(list())\n",
    "            for state_y in range(0, int(self.map[\"length\"] / self.UAV_speed) + 1):\n",
    "                transition[state_x].append(list())\n",
    "                for action in self.action_space:\n",
    "                    next_state = self.transition_dynamics(action, self.UAV_speed, (state_x * self.UAV_speed, state_y * self.UAV_speed))\n",
    "                    reward = self.get_reward(next_state)\n",
    "                    transition[state_x][state_y].append(dict(next_state=next_state,reward=reward))\n",
    "        return transition\n",
    "                    \n",
    "    def step(self, action, speed=-1):\n",
    "        # assume we use the max speed as the default speed, when come near to the opt-position, we can slow down the speed\n",
    "        if speed < 0 or speed >= self.UAV_speed:\n",
    "            speed = self.UAV_speed\n",
    "            \n",
    "        self.UAV_current_pos = self.transition_dynamics(action, speed, self.UAV_current_pos)\n",
    "        self.current_step = self.current_step + 1\n",
    "        done = False\n",
    "        if self.current_step == self.total_steps:\n",
    "            done =  True\n",
    "        return self.UAV_current_pos, self.get_reward(self.UAV_current_pos), done\n",
    "    \n",
    "    def action_sample(self):\n",
    "        return choice(self.action_space)\n",
    "    \n",
    "    def reset(self):\n",
    "        self.current_step = 0\n",
    "        self.UAV_current_pos = self.UAV_initial_pos\n",
    "        #self.users_pos = list()\n",
    "        #for i in range(0, self.number_of_user):\n",
    "        #    self.users_pos.append((randint(0, self.map[\"width\"]), randint(0, self.map[\"length\"])))\n",
    "        return self.UAV_current_pos\n",
    "        \n",
    "    def print_attribute(self):\n",
    "        attrs = vars(self)\n",
    "        print(', '.join(\"%s: %s\" % item for item in attrs.items()))\n",
    "        \n",
    "    def print_locations(self):\n",
    "        print(\"UAV position is: {}\".format(self.UAV_current_pos))\n",
    "        print(\"Users position are: {}\".format(self.users_pos))\n",
    "        \n",
    "    def print_map(self):\n",
    "        x_list = [pos[0] for pos in self.users_pos]\n",
    "        y_list = [pos[1] for pos in self.users_pos]\n",
    "        x_list.append(self.UAV_current_pos[0])\n",
    "        y_list.append(self.UAV_current_pos[1])\n",
    "        \n",
    "        colors = np.array([\"red\", \"green\"])\n",
    "        sizes = []\n",
    "        colors_map = []\n",
    "        for i in range(0, self.number_of_user):\n",
    "            sizes.append(25)\n",
    "            colors_map.append(1)\n",
    "        sizes.append(50)\n",
    "        colors_map.append(0)\n",
    "        plt.scatter(x_list, y_list, c=colors[colors_map], s=sizes) \n",
    "        plt.axis([0, self.map[\"width\"], 0, self.map[\"length\"]])\n",
    "        plt.show()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 543,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment_config = dict(\n",
    "    total_steps = 10,\n",
    "    random_seed = 0,\n",
    "    is_random_env = False,\n",
    "    map=dict(\n",
    "        width=1000,\n",
    "        length=1000,\n",
    "        height=100\n",
    "    ),\n",
    "    number_of_user = 10,\n",
    "    UAV_speed = 20,\n",
    "    UAV_initial_pos = (0, 0),\n",
    "    wireless_parameter = dict(\n",
    "        g0 = 10 ** (-5),\n",
    "        B = 10 ** (6),\n",
    "        Pk = 0.1,\n",
    "        noise = 10 ** (-9)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 544,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action_space: (0, 1, 2, 3), total_steps: 10, current_step: 0, random_seed: 0, map: {'width': 1000, 'length': 1000, 'height': 100}, UAV_speed: 20, UAV_initial_pos: (0, 0), UAV_current_pos: (0, 0), number_of_user: 10, users_pos: [(864, 394), (776, 911), (430, 41), (265, 988), (523, 497), (414, 940), (802, 849), (310, 991), (488, 366), (597, 913)], g0: 1e-05, B: 1000000, Pk: 0.1, noise: 1e-09\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "myGame = UAVEnvironment(environment_config)\n",
    "myGame.print_attribute()\n",
    "myGame.print_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 548,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(policy, config, num_episodes=1, render=False):\n",
    "    env = UAVEnvironment(config)\n",
    "    \n",
    "    rewards = []\n",
    "    for i in range(num_episodes):\n",
    "        obs = env.reset()\n",
    "        # all policy will return a direction and a speed\n",
    "        act_direction, act_speed = policy(obs)\n",
    "        ep_reward = 0\n",
    "        while True:\n",
    "            obs, reward, done = env.step(act_direction, act_speed)\n",
    "            act_direction, act_speed = policy(obs)\n",
    "            ep_reward += reward\n",
    "            if done:\n",
    "                break\n",
    "            if render == True:\n",
    "                clear_output(wait=True)\n",
    "                env.print_attribute()\n",
    "                print(\"Current Step: {}\".format(env.current_step))\n",
    "                print(\"Policy choice direction: {}, speed: {}\".format(act_direction, act_speed))\n",
    "                print(\"UAV current position x: {}, y: {}\".format(env.UAV_current_pos[0], env.UAV_current_pos[1]))\n",
    "                print(\"Current step reward: {}, episodes rewards: {}\".format(reward, ep_reward))\n",
    "                env.print_map()\n",
    "                wait(sleep=0.2)\n",
    "        rewards.append(ep_reward)\n",
    "    return np.mean(rewards)\n",
    "\n",
    "def run(trainer_cls, config=None, reward_threshold=None):\n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 549,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Class for all RL algorithm\n",
    "class UAVTrainer: \n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.env = UAVEnvironment(self.config)\n",
    "    \n",
    "    def train(self):\n",
    "        pass\n",
    "    \n",
    "    def policy(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 550,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action_space: (0, 1, 2, 3), total_steps: 10, current_step: 0, random_seed: 0, map: {'width': 1000, 'length': 1000, 'height': 100}, UAV_speed: 20, UAV_initial_pos: (0, 0), UAV_current_pos: (0, 0), number_of_user: 10, users_pos: [(864, 394), (776, 911), (430, 41), (265, 988), (523, 497), (414, 940), (802, 849), (310, 991), (488, 366), (597, 913)], g0: 1e-05, B: 1000000, Pk: 0.1, noise: 1e-09\n",
      "Mean Reward is: 0.26941655644987067\n"
     ]
    }
   ],
   "source": [
    "# Start from random policy\n",
    "class UAVTrainerRandomPolicy(UAVTrainer):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        \n",
    "    def policy(self, obs):\n",
    "        max_speed = self.env.UAV_speed\n",
    "        return self.env.action_sample(), max_speed\n",
    "\n",
    "random_policy_config = environment_config\n",
    "trainer = UAVTrainerRandomPolicy(random_policy_config)\n",
    "trainer.env.print_attribute()\n",
    "print(\"Mean Reward is: {}\".format(evaluate(trainer.policy, config = random_policy_config, num_episodes=1, render=False))) # Enable render=True can see the agent behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action_space: (0, 1, 2, 3), total_steps: 50, current_step: 0, random_seed: 10, map: {'width': 1000, 'length': 1000, 'height': 10000}, UAV_speed: 20, UAV_initial_pos: (0, 0), UAV_current_pos: (0, 0), number_of_user: 10, users_pos: [(585, 33), (439, 494), (591, 15), (211, 473), (832, 503), (843, 284), (669, 830), (164, 35), (533, 501), (335, 77)], g0: 1e-05, B: 1000000, Pk: 0.1, noise: 1e-09\n",
      "Iteration 100, Mean Reward is: 0.007197806641099489\n",
      "Train converge at i = 100\n"
     ]
    }
   ],
   "source": [
    "import copy\n",
    "\n",
    "# Value Iteration, Tabular, transition dynamic is known, assume only use fixed speed to reduce action space\n",
    "class UAVTrainerValueIteration(UAVTrainer):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.config = config\n",
    "        self.transitions = self.env.get_transition()\n",
    "        self.q_table = []\n",
    "        self.obs_dim = (int(self.env.map[\"width\"] / self.env.UAV_speed), int(self.env.map[\"length\"] / self.env.UAV_speed))\n",
    "        self.act_dim = len(self.env.action_space)\n",
    "        self.gamma = config[\"gamma\"]\n",
    "        \n",
    "        for x in range(0, self.obs_dim[0]+1):\n",
    "            self.q_table.append(list())\n",
    "            for y in range(0, self.obs_dim[1]+1):\n",
    "                self.q_table[x].append(0)\n",
    "            \n",
    "    def get_transition(self, state, act):\n",
    "        transition = self.transitions[state[0]][state[1]][act]\n",
    "        return transition[\"next_state\"], transition[\"reward\"]\n",
    "    \n",
    "    def print_transitions(self):\n",
    "        print(\"Transition width {}, length {}, number of act {}\".format(len(self.transitions), len(self.transitions[0]), len(self.transitions[0][0])))\n",
    "        print(self.transitions)\n",
    "        \n",
    "    def print_table(self):\n",
    "        for j in range(len(self.q_table[0])-1, -1, -1):\n",
    "            for i in range(0, len(self.q_table)):\n",
    "                print(self.q_table[i][j], end =\" \")\n",
    "            print(\"\")\n",
    "            \n",
    "            \n",
    "    def copy_current_table(self):\n",
    "        old_table = []\n",
    "        for x in range(0, self.obs_dim[0]+1):\n",
    "            old_table.append(list())\n",
    "            for y in range(0, self.obs_dim[1]+1):\n",
    "                old_table[x].append(self.q_table[x][y])\n",
    "        return old_table\n",
    "\n",
    "    def update_value_function(self):\n",
    "        old_table = self.copy_current_table()\n",
    "        for state_x in range(self.obs_dim[0] + 1):\n",
    "            for state_y in range(self.obs_dim[1] + 1):\n",
    "                state_value = 0\n",
    "                state_action_values = [0 for i in range(0, self.act_dim)]\n",
    "\n",
    "                for act in range(self.act_dim):\n",
    "                    next_state, reward = self.get_transition((state_x, state_y), act)\n",
    "                    table_x = int(next_state[0] / self.env.UAV_speed)\n",
    "                    table_y = int(next_state[1] / self.env.UAV_speed)\n",
    "                    #print(table_x, table_y)\n",
    "                    state_action_values[act] = state_action_values[act] + reward + self.gamma * old_table[table_x][table_y]   \n",
    "                state_value = np.max(state_action_values)\n",
    "                self.q_table[state_x][state_y] = state_value\n",
    "                #print(\"Update x: {}, y: {} to value {}\".format(state_x, state_y, state_value))\n",
    "            \n",
    "    def train(self):\n",
    "        old_state_value_table = self.copy_current_table()\n",
    "        current_step = 0\n",
    "        while current_step < self.config['max_iteration']:  \n",
    "            current_step = current_step + 1\n",
    "            self.update_value_function()\n",
    "            if current_step % self.config[\"evaluate_interval\"] == 0:\n",
    "                print(\"Iteration {}, Mean Reward is: {}\".format(current_step, evaluate(self.policy, config = self.config, num_episodes=1, render=False)))\n",
    "                #print(\"Iteration {}, Mean Reward is: {}\".format(current_step, 0))\n",
    "                # check exist\n",
    "                stop = True\n",
    "                flag = 0\n",
    "                for x in range(self.obs_dim[0] + 1):\n",
    "                    for y in range(self.obs_dim[1] + 1):\n",
    "                        if abs(self.q_table[x][y] - old_state_value_table[x][y]) > self.config[\"return_threshold\"]:\n",
    "                            stop = False\n",
    "                            flag = 1\n",
    "                    if flag == 1:\n",
    "                        break\n",
    "                if stop == True:\n",
    "                    print(\"Train converge at i = {}\".format(current_step))\n",
    "                    current_step = self.config['max_iteration']\n",
    "                else:\n",
    "                    old_state_value_table = self.copy_current_table()\n",
    "\n",
    "    def policy(self, obs):\n",
    "        table_x = int(obs[0] / self.env.UAV_speed)\n",
    "        table_y = int(obs[1] / self.env.UAV_speed)\n",
    "        next_state_value_list = []\n",
    "        for act in range(0, self.act_dim):\n",
    "            next_state, reward = self.get_transition((table_x, table_y), act)\n",
    "            next_state_x = int(next_state[0] / self.env.UAV_speed)\n",
    "            next_state_y = int(next_state[1] / self.env.UAV_speed)\n",
    "            next_state_value_list.append(self.q_table[next_state_x][next_state_y])\n",
    "        #print(next_state_value_list, act)\n",
    "        act = np.argmax(next_state_value_list)\n",
    "        return act, self.env.UAV_speed\n",
    "\n",
    "value_iteration_config = merge_config(dict(\n",
    "    max_iteration=10000,\n",
    "    total_steps = 50,\n",
    "    number_of_user = 10,\n",
    "    map=dict(\n",
    "        width=1000,\n",
    "        length=1000,\n",
    "        height=10000\n",
    "    ),\n",
    "    evaluate_interval=100,  # don't need to update policy each iteration\n",
    "    gamma=0.9,\n",
    "    return_threshold=1,\n",
    "    random_seed = 10,\n",
    "    is_random_env = False\n",
    "), environment_config)\n",
    "trainer = UAVTrainerValueIteration(value_iteration_config)\n",
    "trainer.env.print_attribute()\n",
    "#trainer.print_transitions()\n",
    "trainer.train()\n",
    "#trainer.print_table()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 552,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "action_space: (0, 1, 2, 3), total_steps: 50, current_step: 49, random_seed: 10, map: {'width': 1000, 'length': 1000, 'height': 10000}, UAV_speed: 20, UAV_initial_pos: (0, 0), UAV_current_pos: (520, 340), number_of_user: 10, users_pos: [(585, 33), (439, 494), (591, 15), (211, 473), (832, 503), (843, 284), (669, 830), (164, 35), (533, 501), (335, 77)], g0: 1e-05, B: 1000000, Pk: 0.1, noise: 1e-09\n",
      "Current Step: 49\n",
      "Policy choice direction: 0, speed: 20\n",
      "UAV current position x: 520, y: 340\n",
      "Current step reward: 0.00014409658377021337, episodes rewards: 0.007053711526565199\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Reward is: 0.007197806641099489\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean Reward is: {}\".format(evaluate(trainer.policy, config = value_iteration_config, num_episodes=1, render=True))) # Enable render=True can see the agent behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 651,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math \n",
    "\n",
    "class UAVEnvironmentComplex(UAVEnvironment):\n",
    "    \"\"\"\n",
    "    Complex UAV environment, action can be compose as (speed, direction), UAV position can be continous float number\n",
    "    \n",
    "    State = (self.UAV_current_pos, self.users_pos [list])\n",
    "    Action = (speed, direction)\n",
    "    \n",
    "    \"\"\"\n",
    "    def __init__(self, config):\n",
    "        super(UAVEnvironmentComplex, self).__init__(config)\n",
    "        delattr(self, \"action_space\") \n",
    "\n",
    "\n",
    "    def transition_dynamics(self, action, state):\n",
    "        # action = (speed, direction), speed with 0 and self.UAV_speed, direction with (0, 2 * pi)\n",
    "        speed = action[0]\n",
    "        direction = action[1]\n",
    "        next_x = self.UAV_current_pos[0] + speed * math.cos(direction)\n",
    "        next_y = self.UAV_current_pos[1] + speed * math.sin(direction)\n",
    "        next_x = max(0, next_x)\n",
    "        next_x = min(self.map[\"width\"], next_x)\n",
    "        next_y = max(0, next_y)\n",
    "        next_y = min(self.map[\"length\"], next_y)\n",
    "        return (next_x, next_y)\n",
    "    \n",
    "    \n",
    "    def step(self, action):\n",
    "        # action = (speed, direction)\n",
    "        # This function return the state = (self.UAV_current_pos, self.users_pos [list])\n",
    "        speed = action[0]\n",
    "        speed = max(0, speed)\n",
    "        speed = min(self.UAV_speed, speed)\n",
    "        \n",
    "        standarded_action = (speed, action[1])\n",
    "        self.UAV_current_pos = self.transition_dynamics(standarded_action, self.UAV_current_pos)\n",
    "        self.current_step = self.current_step + 1\n",
    "        done = False\n",
    "        if self.current_step == self.total_steps:\n",
    "            done =  True\n",
    "        state = (self.UAV_current_pos, self.users_pos)\n",
    "        reward = self.get_reward(self.UAV_current_pos)\n",
    "        return state, reward, done"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 652,
   "metadata": {},
   "outputs": [],
   "source": [
    "environment_config = dict(\n",
    "    total_steps = 50,\n",
    "    is_random_env = True,\n",
    "    map=dict(\n",
    "        width=1000,\n",
    "        length=1000,\n",
    "        height=100\n",
    "    ),\n",
    "    number_of_user = 10,\n",
    "    UAV_speed = 20,\n",
    "    UAV_initial_pos = (500, 500),\n",
    "    wireless_parameter = dict(\n",
    "        g0 = 10 ** (-5),\n",
    "        B = 10 ** (6),\n",
    "        Pk = 0.1,\n",
    "        noise = 10 ** (-9)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 653,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_steps: 50, current_step: 0, map: {'width': 1000, 'length': 1000, 'height': 100}, UAV_speed: 20, UAV_initial_pos: (500, 500), UAV_current_pos: (500, 500), number_of_user: 10, users_pos: [(581, 935), (702, 340), (728, 253), (944, 141), (372, 522), (221, 546), (409, 74), (132, 417), (579, 674), (359, 989)], g0: 1e-05, B: 1000000, Pk: 0.1, noise: 1e-09\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "myGame = UAVEnvironmentComplex(environment_config)\n",
    "myGame.print_attribute()\n",
    "myGame.print_map()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 657,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_complex(policy, config, num_episodes=1, render=False):\n",
    "    env = UAVEnvironmentComplex(config)\n",
    "    rewards = []\n",
    "    for i in range(num_episodes):\n",
    "        obs = env.reset()\n",
    "        # all policy will return a direction and a speed\n",
    "        action = policy(obs)\n",
    "        ep_reward = 0\n",
    "        while True:\n",
    "            obs, reward, done = env.step(action)\n",
    "            action = policy(obs)\n",
    "            ep_reward += reward\n",
    "            if done:\n",
    "                break\n",
    "            if render == True:\n",
    "                clear_output(wait=True)\n",
    "                env.print_locations()\n",
    "                print(\"Current Step: {}\".format(env.current_step))\n",
    "                print(\"Policy choice direction: {}, speed: {}\".format((action[1] * 180 / math.pi), action[0]))\n",
    "                print(\"Current step reward: {}, episodes rewards: {}\".format(reward, ep_reward))\n",
    "                env.print_map()\n",
    "                wait(sleep=0.2)\n",
    "        rewards.append(ep_reward)\n",
    "    return np.mean(rewards)\n",
    "\n",
    "def run(trainer_cls, config=None, reward_threshold=None):\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 658,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic Class for all RL algorithm\n",
    "class UAVComplexTrainer: \n",
    "    def __init__(self, config):\n",
    "        self.config = config\n",
    "        self.env = UAVEnvironment(self.config)\n",
    "    \n",
    "    def train(self):\n",
    "        pass\n",
    "    \n",
    "    def policy(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 660,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UAV position is: (483.7236709613631, 488.1600204406542)\n",
      "Users position are: [(40, 491), (634, 104), (275, 853), (519, 502), (564, 660), (403, 484), (271, 185), (235, 553), (373, 163), (309, 872)]\n",
      "Current Step: 49\n",
      "Policy choice direction: 101.84349341960514, speed: 20\n",
      "Current step reward: 0.3068563440936959, episodes rewards: 15.094853878215863\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYkAAAD8CAYAAACCRVh7AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAXZ0lEQVR4nO3dfZBU9Z3v8fcXhqcBkQfRIKDogkqM61UnStRyifiILlJXzWpcw3VxcW80a+I+xOzdSir3Jqmkandx3VgkJCTBmNXkajZSxsRFRK3UxochelVAhSiREZTh+Zl5+t0/+owMzBzF6Z7pnpn3q6qrz/mdX/f59uHAh/M7p09HSglJkjrSr9wFSJIqlyEhScplSEiSchkSkqRchoQkKZchIUnK9YEhERE/iIiNEfFKm7ZREbEkIlZnzyOz9oiIuyNiTUS8FBFntnnN7Kz/6oiY3TUfR5JUSodzJPEj4LJD2u4ElqaUJgNLs3mAy4HJ2WMuMB8KoQJ8BTgHOBv4SmuwSJIq1weGRErpaWDLIc1XAYuy6UXArDbt96aCZ4ARETEWuBRYklLaklLaCiyhffBIkipMVSdfd0xKaQNASmlDRBydtY8D1rXpV5e15bW3ExFzKRyFMHTo0LNOOeWUTpYoSX3T8uXLN6WUxpTivTobEnmig7b0Pu3tG1NaACwAqKmpSbW1taWrTpL6gIj4Q6neq7NXN72bDSORPW/M2uuACW36jQfWv0+7JKmCdTYkFgOtVyjNBh5u0/6Z7CqnqcD2bFjqMeCSiBiZnbC+JGuTJFWwDxxuioj7gWnAURFRR+EqpW8CP4uIOcBbwLVZ90eBGcAaYA9wE0BKaUtE/B/g+azf/04pHXoyXJJUYaKSbxXuOQlJ+vAiYnlKqaYU7+U3riVJuQwJSVIuQ0KSlMuQkCTlMiQkSbkMCUlSLkNCkpTLkJAk5TIkJEm5DAlJUi5DQpKUy5CQJOUyJCRJuQwJSVIuQ0KSlMuQkCTlMiQkSbkMCUlSLkNCkpTLkNCHsrdxL19e9mWm3DOFTy76JE+ufbLcJUnqQlXlLkA9y9U/u5pla5exr2kfr256lefefo5f3fArLjj+gnKXJqkLeCShw7Z229r3AqLVnsY9fP3pr5exKkldyZDQYduydwsD+g1o175xz8YyVCOpOxgS4t1d73Ln43dy+U8uZ95v57G3cW+H/f74mD9mcNXgg9qGVA3hhtNu6I4yJZWB5yT6uE17NnHa/NPYvn87Dc0NPLX2KR545QGeufkZIuKgvlX9qvjlp3/JzPtnsrNhJ00tTcw8eSa3n3N7maqX1NUMiT7ue8u/x86GnTQ0NwCwt2kvKzet5Kk/PMW0idPa9f/4uI9Td0cdr256ldHVo/nIsI90c8WSupMh0ce9vvn1g05EA6SUWLttbe5r+vfrz6lHn9rFlUmqBJ6T6ONmTJ7B0AFDD2prTs38yfF/UqaKJFUSQ6KPu/qjV3PlSVcypGoIwwcNZ3D/wXztk1/jhJEnlLs0SRXA4aY+rl/044FrHmBV/Spe3/w6Hx/3cY494thylyWpQhgSAmDKmClMGTOl3GVIqjAON0mSchkSkqRchoQkKZchIUnKVVRIRMQXImJFRLwSEfdHxOCIOCEino2I1RHx04gYmPUdlM2vyZZPLMUHkCR1nU6HRESMA/4aqEkpfQzoD1wHfAuYl1KaDGwF5mQvmQNsTSlNAuZl/SRJFazY4aYqYEhEVAHVwAbgQuDBbPkiYFY2fVU2T7Z8ehx6BzlJUkXpdEiklN4G/gl4i0I4bAeWA9tSSk1ZtzpgXDY9DliXvbYp6z/60PeNiLkRURsRtfX19Z0tT5JUAsUMN42kcHRwAnAsMBS4vIOuqfUl77PsQENKC1JKNSmlmjFjxnS2PElSCRQz3HQR8GZKqT6l1Aj8HDgXGJENPwGMB9Zn03XABIBs+ZHAliLWL0nqYsWExFvA1Iiozs4tTAdWAsuAa7I+s4GHs+nF2TzZ8idSSu2OJCRJlaOYcxLPUjgB/Tvg5ey9FgBfBO6IiDUUzjkszF6yEBidtd8B3FlE3ZKkbhCV/J/5mpqaVFtbW+4yJKlHiYjlKaWaUryX37iWJOUyJCRJuQwJSVIuQ0KSlMuQkCTlMiQkSbkMCUlSLkNCkpTLkJAk5TIkJEm5DAlJUi5DQpKUy5CQJOUyJCRJuQwJSVIuQ0KSlMuQkCTlMiQkSbkMCUlSLkNCkpTLkJAk5TIkpArw/NvPc92D13HxvRdz30v3kVIqd0kSAFXlLkDq655a+xQz/n0Gexv3kkj8tu631K6v5a7L7ip3aZJHElK5/cPSf2BP4x4ShaOH3Y27+W7td9mxf0eZK5MMCans1u1Y166tX79+bNqzqQzVSAczJKQyu/KkKxnYf+BBbUcOOpKJIyaWpyCpDUNCKrNvTP8Gp445laEDhjJ80HBGDBrBQ596iH7hX0+VnyeupTIbMXgEy+cu54V3XmDbvm2cN+E8BlUNKndZEmBISBUhIjhz7JnlLkNqx+NZSVIuQ0KSlMuQkCTlMiQkSbkMCUlSrqJCIiJGRMSDEfFqRKyKiE9ExKiIWBIRq7PnkVnfiIi7I2JNRLwUEV7KIUkVrtgjiX8Ffp1SOgU4HVgF3AksTSlNBpZm8wCXA5Ozx1xgfpHrliR1sU6HREQMBy4AFgKklBpSStuAq4BFWbdFwKxs+irg3lTwDDAiIsZ2unJJUpcr5kjiRKAe+GFEvBAR34+IocAxKaUNANnz0Vn/cUDbO5nVZW0HiYi5EVEbEbX19fVFlCdJKlYxIVEFnAnMTymdAezmwNBSR6KDtna/rJJSWpBSqkkp1YwZM6aI8iRJxSomJOqAupTSs9n8gxRC493WYaTseWOb/hPavH48sL6I9UuSulinQyKl9A6wLiJOzpqmAyuBxcDsrG028HA2vRj4THaV01Rge+uwlCSpMhV7g7/PAT+JiIHAG8BNFILnZxExB3gLuDbr+ygwA1gD7Mn6SpIqWFEhkVJ6EajpYNH0Dvom4NZi1idJ6l5+41qSlMvfk+hlNu/ZzC9e/QUAs06Zxejq0WWuSFJPZkj0Is+9/RzT751OYWQPPv/Y51ly4xKmjp9a5sok9VQON/UicxbPYVfDLnY37mZ34252Nezi5sU3l7ssST2YIdGLrKxfeVhtknS4DIle5Pgjj2/fNqJ9myQdLkOiF5l/xXyqB1RT1a+Kqn5VVFdVM/8Kb7YrqfM8cd2LXDrpUl685UXue+k+WlILN55+IyeNPqncZUnqwQyJXmby6Ml89ZNfLXcZknoJh5skSbkMCUlSLkNCkpTLcxJSiTQ2N7L0zaXsa9rHRSdexLCBw8pdklQ0Q0Iqgbe2v8W5C89lZ8NOAFJK/OeN/+ktUdTjOdwk5dm/H375S/jxj2HVqvftetujt7Fh1wZ27N/Bjv072Nmwk+sfuv69+2hJPVWvCYm6HXVcdt9lDPn6EI6bdxz3vXRfuUtST/brX8Mxx8D118NnPwtnnQUXXQQ7dnTY/ek/PE1Lajmobf2O9Wzdt7U7qpW6TK8IiZbUwgU/vIDH33icfU37WLdjHbc8cguPv/F4uUtTiTU0N/DQyoe457l7WL15ddes5PXX4eqrYft22LkTdu2CvXvhN78phEYHOrr9yaCqQQwfNLxrapS6Sa8Iiefefo76PfU0p+b32vY07uHuZ+8uY1Uqtc17NnPKt0/hpodv4u+W/B2nf+d07nnuntKvaN48aGho375/PzzxBKxd227RP1/yz1QPqKZfFP5KVQ+o5msXfo2qfp72U8/WK/bg5pZmgmjX3tTSVIZq1FW++Ztv8vbOt2loPvAP+N8u+Vs+fdqnGTlkZOlW9Mwz0JSz7wwcCCtWwMSJBzVfdOJF/Ndf/Bfza+ezu2E3N51xExeecGHpapLKpFeExNTxUxk2cBi7GnaRKJworB5QzV/V/FWZK1MpLVu77KCAABjUfxAr6ldw/nHnl25F48bBiy92vKylBY4+usNFp3/kdL5z5XdKV4dUAXrFcFP/fv158n88yVljzyIIhg8azjemf4OZJ88sd2kqobPGnkVVHPz/mn1N+5g8anJpV3TbbTB0aMfLjjoKampKuz6pgvWKIwmAk0afxPNzn6exuZGqflVEtB9+Us/2jxf8Iw+teog9jXvY17SP6gHV3Hb2bRwz7JjSrujSS+HGG+HeewsnrFOCIUNgwAD4j/8A9y31IVHJ13HX1NSk2tracpehCrJ5z2bu/X/3Urezjj896U+ZNnFa16wopcLVTAsWwLvvwrRp8Jd/CWPGdM36pBKKiOUppZIc8hoSktTLlDIkesU5CUlS1zAkJEm5DAlJUi5DQpKUy5CQJOUyJCRJuQwJSVIuQ0KSlMuQkCTlMiQkSbkMCUlSrqJDIiL6R8QLEfFINn9CRDwbEasj4qcRMTBrH5TNr8mWTyx23ZKkrlWKI4nbgVVt5r8FzEspTQa2AnOy9jnA1pTSJGBe1k+SVMGKComIGA9cAXw/mw/gQuDBrMsiYFY2fVU2T7Z8evijD5JU0Yo9krgL+HugJZsfDWxLKbX+QHAdMC6bHgesA8iWb8/6HyQi5kZEbUTU1tfXF1meJKkYnQ6JiLgS2JhSWt62uYOu6TCWHWhIaUFKqSalVDPGH3iRpLIq5udLzwNmRsQMYDAwnMKRxYiIqMqOFsYD67P+dcAEoC4iqoAjgS1FrF+S1MU6fSSRUvpSSml8SmkicB3wRErpBmAZcE3WbTbwcDa9OJsnW/5EquSfxZMkdcn3JL4I3BERayicc1iYtS8ERmftdwB3dsG6JUklVMxw03tSSk8CT2bTbwBnd9BnH3BtKdYnSeoefuNakpTLkJAk5TIkJEm5DAlJUi5DQpKUy5CQJOUyJCRJuQwJSVIuQ0KSlMuQkCTlMiQkSbkMCUlSLkNCkpTLkJAk5TIkJEm5DAlJUi5DQpKUy5CQJOUyJCRJuQwJSVIuQ0KSlMuQkCTlMiQkSbkMCUlSLkNCkpTLkJAk5TIkJEm5DAlJUi5DQpKUy5CQJOUyJCRJuQwJSVIuQ0KSlMuQkCTl6nRIRMSEiFgWEasiYkVE3J61j4qIJRGxOnsembVHRNwdEWsi4qWIOLNUH0KS1DWKOZJoAv4mpTQFmArcGhEfBe4ElqaUJgNLs3mAy4HJ2WMuML+IdUuSukGnQyKltCGl9LtseiewChgHXAUsyrotAmZl01cB96aCZ4ARETG205VLkrpcVSneJCImAmcAzwLHpJQ2QCFIIuLorNs4YF2bl9VlbRsOea+5FI40OO6440pRnt7Hzv07WfzaYhqaG5h58kxGV48ud0mSKkjRIRERw4CHgM+nlHZERG7XDtpSu4aUFgALAGpqatotV+ms2LiC8394Pk0tTaSU+NyvPsejNzzKBcdfUO7SJFWIoq5uiogBFALiJymln2fN77YOI2XPG7P2OmBCm5ePB9YXs34V55ZHbmHbvm3satjF7sbd7G7czexfzCYls1lSQTFXNwWwEFiVUvqXNosWA7Oz6dnAw23aP5Nd5TQV2N46LKXyeOGdF9q1rdu+jj2Ne8pQjaRKVMyRxHnAjcCFEfFi9pgBfBO4OCJWAxdn8wCPAm8Aa4DvAZ8tYt0qgT8a+Uft2kYOGUn1gOoyVCOpEnX6nERK6Td0fJ4BYHoH/RNwa2fXp9K7+/K7ueLfr6ChuYGW1MLgqsH82+X/xvucV+oyv9/ye779/LfZsHMDf3bqnzHrlFllqUPSwaKSx59rampSbW1tucvo1dZsWcOPXvwR+5v38+en/Tmnf+T0bq/h5Xdf5twfnMu+pn00tTQxdMBQbj7zZu667K5ur0XqDSJieUqppiTvZUio3GY9MIvFry0mtbnYbXDVYNZ9YR1HVR9VxsqknqmUIeG9m1R2r29+/aCAABjQbwB1O+rKVJGkVoaEyu7SSZcysP/Adu1TjppShmoktWVIqOy+fMGXmTRqEkcMPIIjBh7BkKoh3Pff72NQ1aBylyb1eSW5LYdUjJFDRvLy/3yZp//wNPW765l+4nRGDRlV7rIkYUioQvSLfkybOK3cZUg6hMNNkqRchoQkKZchIUnKZUhIknIZEpKkXIaE1Mu9s+sdbl58M5PunsSsB2axsn5luUtSD+IlsFIv1tDcwDnfP4f1O9fT1NLEG1vf4Ik3n2DlrSsZP3x8uctTD+CRhNSLPbr6Ubbu3UpTSxMAicT+5v0s/N3CMlemnsKQkHqxLXu30JJaDmpraG5g4+6NOa+QDmZISL3YZZMuozk1H9RWPaCaa0+9tkwVqacxJKRe7NgjjmXRrEUMGziMIwYeweCqwXzxvC96CxQdNk9cS73cp079FDNPnsmaLWuYMHwCRw4+stwlqQcxJKQ+YHDVYD529MfKXYZ6IIebJEm5DAlJUi5DQpKUy5CQJOUyJCRJuQwJSVIuQ0KSlMuQkCTlMiQkSbkMCUlSLkNCkpTLkJAk5TIkJEm5DAlJUi5DQpKUq9tDIiIui4jXImJNRNzZ3euXJB2+bg2JiOgP3ANcDnwUuD4iPtqdNUiSDl93H0mcDaxJKb2RUmoAHgCu6uYaJEmHqbt/vnQcsK7NfB1wTtsOETEXmJvN7o+IV7qptkp3FLCp3EVUCLfFAW6LA9wWB5xcqjfq7pCIDtrSQTMpLQAWAEREbUqppjsKq3RuiwPcFge4LQ5wWxwQEbWleq/uHm6qAya0mR8PrO/mGiRJh6m7Q+J5YHJEnBARA4HrgMXdXIMk6TB163BTSqkpIm4DHgP6Az9IKa14n5cs6J7KegS3xQFuiwPcFge4LQ4o2baIlNIH95Ik9Ul+41qSlMuQkCTlqtiQ6Gu374iICRGxLCJWRcSKiLg9ax8VEUsiYnX2PDJrj4i4O9s+L0XEmeX9BKUVEf0j4oWIeCSbPyEins22w0+zCx+IiEHZ/Jps+cRy1t0VImJERDwYEa9m+8cn+uJ+ERFfyP5uvBIR90fE4L60X0TEDyJiY9vvjnVmP4iI2Vn/1REx+4PWW5Eh0Udv39EE/E1KaQowFbg1+8x3AktTSpOBpdk8FLbN5OwxF5jf/SV3qduBVW3mvwXMy7bDVmBO1j4H2JpSmgTMy/r1Nv8K/DqldApwOoXt0qf2i4gYB/w1UJNS+hiFC1+uo2/tFz8CLjuk7UPtBxExCvgKhS8xnw18pTVYcqWUKu4BfAJ4rM38l4Avlbuubt4GDwMXA68BY7O2scBr2fR3gevb9H+vX09/UPj+zFLgQuARCl/C3ARUHbp/ULhS7hPZdFXWL8r9GUq4LYYDbx76mfrafsGBuzWMyv6cHwEu7Wv7BTAReKWz+wFwPfDdNu0H9evoUZFHEnR8+45xZaql22WHxmcAzwLHpJQ2AGTPR2fdevM2ugv4e6Almx8NbEspNWXzbT/re9shW749699bnAjUAz/Mht++HxFD6WP7RUrpbeCfgLeADRT+nJfTd/eLVh92P/jQ+0elhsQH3r6jt4qIYcBDwOdTSjver2sHbT1+G0XElcDGlNLyts0ddE2Hsaw3qALOBOanlM4AdnNgSKEjvXJ7ZEMiVwEnAMcCQykMqRyqr+wXHyTv83/o7VKpIdEnb98REQMoBMRPUko/z5rfjYix2fKxwMasvbduo/OAmRGxlsJdgi+kcGQxIiJav/zZ9rO+tx2y5UcCW7qz4C5WB9SllJ7N5h+kEBp9bb+4CHgzpVSfUmoEfg6cS9/dL1p92P3gQ+8flRoSfe72HRERwEJgVUrpX9osWgy0XoEwm8K5itb2z2RXMUwFtrcedvZkKaUvpZTGp5QmUvhzfyKldAOwDLgm63bodmjdPtdk/XvN/xhTSu8A6yKi9a6e04GV9LH9gsIw09SIqM7+rrRuhz65X7TxYfeDx4BLImJkdnR2SdaWr9wnYt7nBM0M4HXg98D/Knc93fB5z6dw2PcS8GL2mEFhHHUpsDp7HpX1DwpXgP0eeJnCVR9l/xwl3ibTgEey6ROB54A1wP8FBmXtg7P5NdnyE8tddxdsh/8G1Gb7xi+AkX1xvwC+CrwKvAL8GBjUl/YL4H4K52MaKRwRzOnMfgD8RbZd1gA3fdB6vS2HJClXpQ43SZIqgCEhScplSEiSchkSkqRchoQkKZchIUnKZUhIknL9f03rSRR58mwLAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Reward is: 15.405359339968964\n"
     ]
    }
   ],
   "source": [
    "# Start from random policy\n",
    "class UAVComplexTrainerRandomPolicy(UAVComplexTrainer):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        \n",
    "    def policy(self, obs):\n",
    "        max_speed = self.env.UAV_speed\n",
    "        #random_direction = random.uniform(0, 1) * 2 * math.pi\n",
    "        random_direction = math.pi * 2 * random.uniform(0, 1)\n",
    "        action = (max_speed, random_direction)\n",
    "        return action\n",
    "\n",
    "random_policy_config = environment_config\n",
    "trainer = UAVComplexTrainerRandomPolicy(random_policy_config)\n",
    "print(\"Mean Reward is: {}\".format(evaluate_complex(trainer.policy, config = random_policy_config, num_episodes=1, render=True))) # Enable render=True can see the agent behavior"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
